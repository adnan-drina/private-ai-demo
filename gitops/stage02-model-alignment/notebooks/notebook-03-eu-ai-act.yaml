apiVersion: v1
data:
  notebook.ipynb: "{\n \"cells\": [\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\":
    {},\n   \"source\": [\n    \"# EU AI Act RAG Demo - Compliance Assistant\\n\",\n
    \   \"\\n\",\n    \"This notebook demonstrates **Retrieval-Augmented Generation
    (RAG)** for EU AI Act compliance queries.\\n\",\n    \"\\n\",\n    \"## Architecture\\n\",\n
    \   \"\\n\",\n    \"```\\n\",\n    \"User Question → Llama Stack Agent → Milvus
    Vector Search → Retrieved Context → Mistral 24B → Grounded Answer\\n\",\n    \"```\\n\",\n
    \   \"\\n\",\n    \"## Key Features\\n\",\n    \"\\n\",\n    \"- **Baseline vs.
    RAG Comparison**: See the difference between generic LLM responses and RAG-enhanced
    answers\\n\",\n    \"- **Source Attribution**: Every answer includes precise citations
    (Article, Page, Document)\\n\",\n    \"- **Compliance Use Case**: Demonstrates
    AI for legal/regulatory scenarios\\n\",\n    \"- **Universal Relevance**: EU AI
    Act applies globally to any AI deployed in EU\\n\"\n   ]\n  },\n  {\n   \"cell_type\":
    \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Setup\\n\"\n   ]\n
    \ },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\":
    {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Install required packages\\n\",\n
    \   \"!pip install -q llama-stack-client openai\\n\"\n   ]\n  },\n  {\n   \"cell_type\":
    \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\":
    [],\n   \"source\": [\n    \"import os\\n\",\n    \"import uuid\\n\",\n    \"from
    openai import OpenAI\\n\",\n    \"from llama_stack_client import LlamaStackClient,
    Agent, AgentEventLogger\\n\",\n    \"\\n\",\n    \"# Configuration\\n\",\n    \"MISTRAL_URL
    = \\\"http://mistral-24b-quantized-predictor.private-ai-demo.svc.cluster.local/v1\\\"\\n\",\n
    \   \"LLAMASTACK_URL = \\\"http://llamastack.private-ai-demo.svc:8321\\\"\\n\",\n
    \   \"MODEL_ID = \\\"mistral-24b-quantized\\\"\\n\",\n    \"\\n\",\n    \"# Initialize
    clients\\n\",\n    \"vllm_client = OpenAI(base_url=MISTRAL_URL, api_key=\\\"dummy\\\")\\n\",\n
    \   \"llama_client = LlamaStackClient(base_url=LLAMASTACK_URL)\\n\",\n    \"\\n\",\n
    \   \"print(\\\"✅ Clients initialized\\\")\\n\",\n    \"print(f\\\"   Direct vLLM:
    {MISTRAL_URL}\\\")\\n\",\n    \"print(f\\\"   Llama Stack: {LLAMASTACK_URL}\\\")\\n\"\n
    \  ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\":
    [\n    \"## Test Questions\\n\",\n    \"\\n\",\n    \"We'll test 4 types of queries
    that showcase RAG's value for compliance scenarios.\\n\"\n   ]\n  },\n  {\n   \"cell_type\":
    \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\":
    [],\n   \"source\": [\n    \"# Test questions covering different aspects of the
    EU AI Act\\n\",\n    \"QUESTIONS = {\\n\",\n    \"    \\\"prohibited\\\": \\\"According
    to Article 5 of the EU AI Act, what AI practices are explicitly prohibited? List
    only the distinct categories found in the retrieved context.\\\",\\n\",\n    \"
    \   \\\"high_risk\\\": \\\"Is an AI-powered CV screening tool for hiring considered
    high-risk under the EU AI Act? Why or why not?\\\",\\n\",\n    \"    \\\"timeline\\\":
    \\\"When do the main obligations of the EU AI Act come into force? What are the
    key dates?\\\",\\n\",\n    \"    \\\"gpai\\\": \\\"What are the specific obligations
    for General Purpose AI (GPAI) models under the EU AI Act?\\\"\\n\",\n    \"}\\n\",\n
    \   \"\\n\",\n    \"# We'll use the \\\"high_risk\\\" question for the main demo\\n\",\n
    \   \"DEMO_QUESTION = QUESTIONS[\\\"high_risk\\\"]\\n\",\n    \"\\n\",\n    \"print(\\\"\U0001F4CB
    Test Questions:\\\")\\n\",\n    \"for key, question in QUESTIONS.items():\\n\",\n
    \   \"    print(f\\\"\\\\n{key.upper()}:\\\")\\n\",\n    \"    print(f\\\"  {question}\\\")\"\n
    \  ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\":
    [\n    \"## Scenario 1: Baseline (No RAG)\\n\",\n    \"\\n\",\n    \"First, let's
    ask the model **without RAG**. The model will respond based only on its training
    data.\\n\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\":
    null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"print(\\\"=\\\"*70)\\n\",\n
    \   \"print(\\\"BASELINE RESPONSE (No RAG - Direct vLLM)\\\")\\n\",\n    \"print(\\\"=\\\"*70)\\n\",\n
    \   \"print()\\n\",\n    \"print(f\\\"Question: {DEMO_QUESTION}\\\")\\n\",\n    \"print()\\n\",\n
    \   \"\\n\",\n    \"# Call vLLM directly (no RAG)\\n\",\n    \"response_baseline
    = vllm_client.chat.completions.create(\\n\",\n    \"    model=MODEL_ID,\\n\",\n
    \   \"    messages=[{\\\"role\\\": \\\"user\\\", \\\"content\\\": DEMO_QUESTION}],\\n\",\n
    \   \"    max_tokens=500\\n\",\n    \")\\n\",\n    \"\\n\",\n    \"baseline_answer
    = response_baseline.choices[0].message.content\\n\",\n    \"print(baseline_answer)\\n\",\n
    \   \"print()\\n\",\n    \"print(\\\"=\\\"*70)\\n\"\n   ]\n  },\n  {\n   \"cell_type\":
    \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### ⚠️ Issues with
    Baseline Response:\\n\",\n    \"\\n\",\n    \"- Generic, may be outdated\\n\",\n
    \   \"- No specific citations\\n\",\n    \"- No reference to actual EU AI Act
    text\\n\",\n    \"- Vague recommendations\\n\"\n   ]\n  },\n  {\n   \"cell_type\":
    \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Scenario 2: RAG
    (With Llama Stack Agent)\\n\",\n    \"\\n\",\n    \"Now let's use **RAG with the
    Llama Stack Agent**. The agent will:\\n\",\n    \"1. Search for relevant EU AI
    Act content in Milvus\\n\",\n    \"2. Retrieve precise articles and sections\\n\",\n
    \   \"3. Generate an answer grounded in the actual legal text\\n\"\n   ]\n  },\n
    \ {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\":
    {},\n   \"outputs\": [],\n   \"source\": [\n    \"print(\\\"=\\\"*70)\\n\",\n
    \   \"print(\\\"RAG RESPONSE (With Vector Retrieval - Llama Stack Agent)\\\")\\n\",\n
    \   \"print(\\\"=\\\"*70)\\n\",\n    \"print()\\n\",\n    \"print(f\\\"Question:
    {DEMO_QUESTION}\\\")\\n\",\n    \"print()\\n\",\n    \"\\n\",\n    \"try:\\n\",\n
    \   \"    # Create RAG agent using high-level API (Red Hat pattern)\\n\",\n    \"
    \   rag_agent = Agent(\\n\",\n    \"        llama_client,\\n\",\n    \"        model=MODEL_ID,
    \ # Note: \\\"model\\\" not \\\"model_id\\\" for Agent class!\\n\",\n    \"        instructions=(\\n\",\n
    \   \"            \\\"You are an EU AI Act compliance assistant. \\\"\\n\",\n
    \   \"            \\\"Answer questions using ONLY information from the retrieved
    EU AI Act documents. \\\"\\n\",\n    \"            \\\"\\\\n\\\"\\n\",\n    \"
    \           \\\"For list-based questions about prohibited practices or similar:\\\\n\\\"\\n\",\n
    \   \"            \\\"- State how many items the retrieved context contains\\\\n\\\"\\n\",\n
    \   \"            \\\"- List each distinct item ONCE with [OJ p.X, Art.Y] citation\\\\n\\\"\\n\",\n
    \   \"            \\\"- If items look similar, they are likely the same - list
    only once\\\\n\\\"\\n\",\n    \"            \\\"- STOP immediately after listing
    all distinct items\\\\n\\\"\\n\",\n    \"            \\\"\\\\n\\\"\\n\",\n    \"
    \           \\\"For analytical questions (e.g., 'is X considered high-risk'):\\\\n\\\"\\n\",\n
    \   \"            \\\"- Provide a clear, complete explanation\\\\n\\\"\\n\",\n
    \   \"            \\\"- Reference specific Articles and Annexes with citations\\\\n\\\"\\n\",\n
    \   \"            \\\"- Explain the reasoning and criteria\\\\n\\\"\\n\",\n    \"
    \           \\\"\\\\n\\\"\\n\",\n    \"            \\\"If information is not in
    the sources, say 'Not found in sources.'\\\"\\n\",\n    \"        ),\\n\",\n    \"
    \       tools=[\\n\",\n    \"            {\\n\",\n    \"                \\\"name\\\":
    \\\"builtin::rag/knowledge_search\\\",\\n\",\n    \"                \\\"args\\\":
    {\\\"vector_db_ids\\\": [\\\"rag_documents\\\"]},\\n\",\n    \"            }\\n\",\n
    \   \"        ],\\n\",\n    \"    )\\n\",\n    \"    \\n\",\n    \"    print(\\\"✅
    Agent created\\\")\\n\",\n    \"    print()\\n\",\n    \"    \\n\",\n    \"    #
    Create session and query\\n\",\n    \"    session_id = rag_agent.create_session(session_name=f\\\"eu-ai-act-demo-{uuid.uuid4().hex[:8]}\\\")\\n\",\n
    \   \"    print(f\\\"✅ Session created: {session_id}\\\")\\n\",\n    \"    print()\\n\",\n
    \   \"    \\n\",\n    \"    # Ask question with RAG (streaming)\\n\",\n    \"
    \   response = rag_agent.create_turn(\\n\",\n    \"        messages=[{\\\"role\\\":
    \\\"user\\\", \\\"content\\\": DEMO_QUESTION}],\\n\",\n    \"        session_id=session_id,\\n\",\n
    \   \"        stream=True,\\n\",\n    \"    )\\n\",\n    \"    \\n\",\n    \"
    \   # Capture and log the response\\n\",\n    \"    rag_answer = \\\"\\\"\\n\",\n
    \   \"    for log in AgentEventLogger().log(response):\\n\",\n    \"        log.print()\\n\",\n
    \   \"        # Capture all content chunks (streaming tokens)\\n\",\n    \"        if
    hasattr(log, 'content') and log.content:\\n\",\n    \"            rag_answer +=
    log.content\\n\",\n    \"    \\n\",\n    \"    print()\\n\",\n    \"    \\n\",\n
    \   \"except Exception as e:\\n\",\n    \"    print(f\\\"❌ Error: {e}\\\")\\n\",\n
    \   \"    print(\\\"\\\\nℹ️  Note: RAG requires documents to be ingested into
    Milvus.\\\")\\n\",\n    \"    print(\\\"   Run the Tekton pipeline to process
    documents first.\\\")\\n\",\n    \"    rag_answer = None\\n\",\n    \"\\n\",\n
    \   \"print(\\\"=\\\"*70)\\n\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n
    \  \"metadata\": {},\n   \"source\": []\n  },\n  {\n   \"cell_type\": \"markdown\",\n
    \  \"metadata\": {},\n   \"source\": [\n    \"## Side-by-Side Comparison\\n\"\n
    \  ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n
    \  \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"import textwrap\\n\",\n
    \   \"\\n\",\n    \"def print_comparison(baseline, rag):\\n\",\n    \"    print(\\\"=\\\"*140)\\n\",\n
    \   \"    print(f\\\"{'BASELINE (No RAG)':^70} | {'RAG (With Retrieval)':^70}\\\")\\n\",\n
    \   \"    print(\\\"=\\\"*140)\\n\",\n    \"    \\n\",\n    \"    baseline_lines
    = textwrap.wrap(baseline or \\\"N/A\\\", width=68)\\n\",\n    \"    rag_lines
    = textwrap.wrap(rag or \\\"N/A\\\", width=68)\\n\",\n    \"    \\n\",\n    \"
    \   max_lines = max(len(baseline_lines), len(rag_lines))\\n\",\n    \"    \\n\",\n
    \   \"    for i in range(max_lines):\\n\",\n    \"        baseline_line = baseline_lines[i]
    if i < len(baseline_lines) else \\\"\\\"\\n\",\n    \"        rag_line = rag_lines[i]
    if i < len(rag_lines) else \\\"\\\"\\n\",\n    \"        print(f\\\"{baseline_line:68}
    | {rag_line:68}\\\")\\n\",\n    \"    \\n\",\n    \"    print(\\\"=\\\"*140)\\n\",\n
    \   \"\\n\",\n    \"if rag_answer:\\n\",\n    \"    print_comparison(baseline_answer,
    rag_answer)\\n\",\n    \"else:\\n\",\n    \"    print(\\\"⚠️  RAG answer not available
    - documents may need to be ingested\\\")\\n\"\n   ]\n  },\n  {\n   \"cell_type\":
    \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Test All Questions\\n\",\n
    \   \"\\n\",\n    \"Let's test all 4 question types to see RAG's performance across
    different scenarios.\\n\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\":
    null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"def
    test_question_with_rag(question, question_type):\\n\",\n    \"    \\\"\\\"\\\"Test
    a question with RAG\\\"\\\"\\\"\\n\",\n    \"    print(f\\\"\\\\n{'='*70}\\\")\\n\",\n
    \   \"    print(f\\\"TEST: {question_type.upper()}\\\")\\n\",\n    \"    print(f\\\"{'='*70}\\\")\\n\",\n
    \   \"    print(f\\\"\\\\nQuestion: {question}\\\")\\n\",\n    \"    print()\\n\",\n
    \   \"    \\n\",\n    \"    try:\\n\",\n    \"        # Create new session for
    each question using the Agent class\\n\",\n    \"        new_session_id = rag_agent.create_session(session_name=f\\\"test-{question_type}-{uuid.uuid4().hex[:8]}\\\")\\n\",\n
    \   \"        \\n\",\n    \"        # Ask question with streaming\\n\",\n    \"
    \       response = rag_agent.create_turn(\\n\",\n    \"            messages=[{\\\"role\\\":
    \\\"user\\\", \\\"content\\\": question}],\\n\",\n    \"            session_id=new_session_id,\\n\",\n
    \   \"            stream=True,\\n\",\n    \"        )\\n\",\n    \"        \\n\",\n
    \   \"        # Capture and log the response\\n\",\n    \"        answer = \\\"\\\"\\n\",\n
    \   \"        for log in AgentEventLogger().log(response):\\n\",\n    \"            log.print()\\n\",\n
    \   \"            # Capture all content chunks (streaming tokens)\\n\",\n    \"
    \           if hasattr(log, 'content') and log.content:\\n\",\n    \"                answer
    += log.content\\n\",\n    \"        \\n\",\n    \"        print()\\n\",\n    \"
    \       return answer\\n\",\n    \"        \\n\",\n    \"    except Exception
    as e:\\n\",\n    \"        print(f\\\"❌ Error: {e}\\\")\\n\",\n    \"        import
    traceback\\n\",\n    \"        traceback.print_exc()\\n\",\n    \"        return
    None\\n\",\n    \"\\n\",\n    \"# Test all questions if agent is available\\n\",\n
    \   \"if rag_answer and 'rag_agent' in locals():\\n\",\n    \"    results = {}\\n\",\n
    \   \"    for q_type, question in QUESTIONS.items():\\n\",\n    \"        if q_type
    != \\\"high_risk\\\":  # Already tested\\n\",\n    \"            results[q_type]
    = test_question_with_rag(question, q_type)\\n\",\n    \"    \\n\",\n    \"    print(\\\"\\\\n✅
    All questions tested!\\\")\\n\",\n    \"else:\\n\",\n    \"    print(\\\"⚠️  Skipping
    additional tests - agent not available\\\")\\n\"\n   ]\n  },\n  {\n   \"cell_type\":
    \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Business Value:
    Compliance Assistant\\n\",\n    \"\\n\",\n    \"### Why This Matters for Enterprises\\n\",\n
    \   \"\\n\",\n    \"**1. Compliance Cost Reduction**\\n\",\n    \"- ❌ Without
    RAG: Manual legal review, expensive consultants, weeks of research\\n\",\n    \"-
    ✅ With RAG: Instant, accurate compliance guidance with citations\\n\",\n    \"\\n\",\n
    \   \"**2. Risk Mitigation**\\n\",\n    \"- ❌ Without RAG: Generic answers, potential
    non-compliance, fines up to €35M\\n\",\n    \"- ✅ With RAG: Precise, cited answers
    grounded in actual legal text\\n\",\n    \"\\n\",\n    \"**3. Speed to Market**\\n\",\n
    \   \"- ❌ Without RAG: Weeks to understand requirements\\n\",\n    \"- ✅ With
    RAG: Minutes to get actionable guidance\\n\",\n    \"\\n\",\n    \"**4. Global
    Relevance**\\n\",\n    \"- EU AI Act applies to ANY AI system deployed in the
    EU\\n\",\n    \"- Affects US, Asian, and global companies\\n\",\n    \"- Penalties:
    Up to 7% of global annual turnover\\n\",\n    \"\\n\",\n    \"### Use Cases Beyond
    EU AI Act\\n\",\n    \"\\n\",\n    \"This same architecture works for:\\n\",\n
    \   \"- **Legal**: Contract analysis, case law research\\n\",\n    \"- **Healthcare**:
    Clinical guidelines, drug interactions\\n\",\n    \"- **Finance**: Regulatory
    compliance (GDPR, MiFID II, etc.)\\n\",\n    \"- **Manufacturing**: Safety standards,
    quality procedures\\n\",\n    \"- **Any domain** with complex documentation requirements\\n\"\n
    \  ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\":
    [\n    \"## Red Hat AI Four Pillars\\n\",\n    \"\\n\",\n    \"This demo showcases
    all four pillars:\\n\",\n    \"\\n\",\n    \"### 1. ✅ Efficient Inferencing\\n\",\n
    \   \"- Quantized Mistral 24B (4-bit compression)\\n\",\n    \"- 50%+ cost savings
    vs. full precision\\n\",\n    \"- Tool calling for efficient RAG retrieval\\n\",\n
    \   \"\\n\",\n    \"### 2. ✅ Simplified Data Connection\\n\",\n    \"- **Docling**:
    AI-powered document processing (tables, equations, annexes)\\n\",\n    \"- **Tekton
    Pipeline**: Automated ingestion workflow\\n\",\n    \"- **Milvus**: Enterprise
    vector database\\n\",\n    \"- **Llama Stack**: Unified RAG runtime\\n\",\n    \"\\n\",\n
    \   \"### 3. ✅ Hybrid Cloud Flexibility\\n\",\n    \"- All data on-premise (sovereign
    AI)\\n\",\n    \"- Multi-tenant architecture (`ai-infrastructure` shared services)\\n\",\n
    \   \"- GitOps-managed deployments\\n\",\n    \"- Air-gap ready\\n\",\n    \"\\n\",\n
    \   \"### 4. ✅ Agentic AI Delivery\\n\",\n    \"- Llama Stack Agent with tool
    calling\\n\",\n    \"- Autonomous retrieval and generation\\n\",\n    \"- Foundation
    for Stage 3 (MCP servers)\\n\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n
    \  \"metadata\": {},\n   \"source\": [\n    \"## Summary\\n\",\n    \"\\n\",\n
    \   \"**What We Demonstrated:**\\n\",\n    \"- ✅ RAG significantly improves answer
    quality for compliance queries\\n\",\n    \"- ✅ Source attribution builds trust
    and auditability\\n\",\n    \"- ✅ Automated document processing (Tekton pipeline)\\n\",\n
    \   \"- ✅ Enterprise-grade architecture (Llama Stack, Milvus, vLLM)\\n\",\n    \"-
    ✅ Red Hat AI Four Pillars in action\\n\",\n    \"\\n\",\n    \"**Key Takeaway:**
    \ \\n\",\n    \"RAG transforms LLMs from generic chatbots into **precise, auditable
    compliance assistants** that can save enterprises millions in legal review costs
    while mitigating regulatory risk.\\n\",\n    \"\\n\",\n    \"---\\n\",\n    \"\\n\",\n
    \   \"**Status**: ✅ Production Ready  \\n\",\n    \"**Demo Time**: 10-15 minutes
    \ \\n\",\n    \"**Audience**: Legal, Compliance, Risk Management, Enterprise AI\\n\"\n
    \  ]\n  }\n ],\n \"metadata\": {\n  \"language_info\": {\n   \"name\": \"python\"\n
    \ }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 2\n}\n"
kind: ConfigMap
metadata:
  creationTimestamp: null
  name: notebook-03-eu-ai-act
