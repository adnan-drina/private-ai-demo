---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: trustyai-lmeval-provider
  namespace: private-ai-demo
  labels:
    app: trustyai-lmeval-provider
    app.kubernetes.io/name: trustyai-provider
    app.kubernetes.io/component: evaluation
    app.kubernetes.io/part-of: llama-stack
  annotations:
    description: "TrustyAI LM-Eval provider for Llama Stack evaluation API"
    opendatahub.io/dashboard: "true"
    openshift.io/display-name: "TrustyAI Eval Provider"
    app.openshift.io/connects-to: '["llama-stack"]'
spec:
  replicas: 1
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 0
      maxSurge: 1
  selector:
    matchLabels:
      app: trustyai-lmeval-provider
  template:
    metadata:
      labels:
        app: trustyai-lmeval-provider
        app.kubernetes.io/name: trustyai-provider
        app.kubernetes.io/component: evaluation
        app.kubernetes.io/part-of: llama-stack
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: trustyai-provider
      
      # Security context
      securityContext:
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      
      containers:
      - name: provider
        image: quay.io/trustyai/llama-stack-provider-lmeval:latest
        imagePullPolicy: Always
        
        ports:
        - name: http
          containerPort: 8080
          protocol: TCP
        - name: metrics
          containerPort: 9090
          protocol: TCP
        
        env:
        # Kubernetes Configuration
        - name: KUBERNETES_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        
        # TrustyAI Configuration
        - name: TRUSTYAI_LM_EVAL_NAMESPACE
          value: "private-ai-demo"
        
        # TLS Configuration (internal cluster communication)
        - name: TRUSTYAI_LMEVAL_TLS
          value: "false"
        
        # vLLM Model Endpoints (from Stage 1)
        # NOTE: These will be dynamically injected by deploy.sh
        - name: VLLM_URL_QUANTIZED
          value: "${MISTRAL_QUANTIZED_URL}/v1/completions"
        
        - name: VLLM_URL_FULL
          value: "${MISTRAL_FULL_URL}/v1/completions"
        
        # Model tokenizer IDs (HuggingFace)
        - name: TOKENIZER_QUANTIZED
          value: "RedHatAI/Mistral-Small-24B-Instruct-2501-quantized.w4a16"
        
        - name: TOKENIZER_FULL
          value: "mistralai/Mistral-Small-24B-Instruct-2501"
        
        # HuggingFace token for datasets and tokenizers
        - name: HF_TOKEN
          valueFrom:
            secretKeyRef:
              name: huggingface-token
              key: HF_TOKEN
              optional: false
        
        # Logging Configuration
        - name: LOG_LEVEL
          value: "INFO"
        
        - name: LOG_FORMAT
          value: "json"
        
        # Provider Configuration
        - name: PROVIDER_PORT
          value: "8080"
        
        - name: PROVIDER_HOST
          value: "0.0.0.0"
        
        # Timeouts
        - name: EVAL_TIMEOUT
          value: "3600"  # 1 hour max per evaluation
        
        - name: POLL_INTERVAL
          value: "10"  # Check LMEvalJob status every 10 seconds
        
        # Resource limits for eval jobs (passed to LMEvalJob)
        - name: DEFAULT_SAMPLE_LIMIT
          value: "100"
        
        - name: DEFAULT_BATCH_SIZE
          value: "1"
        
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        
        # Security context for container
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          runAsNonRoot: true
        
        # Health checks
        readinessProbe:
          httpGet:
            path: /health
            port: http
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 3
          successThreshold: 1
          failureThreshold: 3
        
        livenessProbe:
          httpGet:
            path: /health
            port: http
            scheme: HTTP
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 3
        
        # Startup probe (for slow starts)
        startupProbe:
          httpGet:
            path: /health
            port: http
            scheme: HTTP
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          successThreshold: 1
          failureThreshold: 12  # 60 seconds max startup time
      
      # Restart policy
      restartPolicy: Always
      
      # DNS configuration
      dnsPolicy: ClusterFirst
      
      # Termination grace period
      terminationGracePeriodSeconds: 30

