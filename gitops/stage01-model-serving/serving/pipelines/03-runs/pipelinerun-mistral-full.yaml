apiVersion: tekton.dev/v1
kind: PipelineRun
metadata:
  generateName: mistral-24b-full-
  namespace: private-ai-demo
  labels:
    app.kubernetes.io/name: mistral-24b-full-pipeline
    app.kubernetes.io/component: pipeline-run
    app.kubernetes.io/part-of: private-ai-demo
    tekton.dev/pipeline: modelcar-build-deploy
  annotations:
    argocd.argoproj.io/hook: Skip
    description: "Pipeline run for Mistral 24B Full Precision model"
spec:
  taskRunTemplate:
    serviceAccountName: model-pipeline-sa
  podTemplate:
    securityContext:
      fsGroup: 1001  # All tasks share same GID for PVC access
      runAsUser: 1001  # Consistent UID across all tasks
  pipelineRef:
    name: modelcar-build-deploy-v2
  
  params:
    # Model source
    - name: hf_repo
      value: "mistralai/Mistral-Small-24B-Instruct-2501"
    - name: hf_revision
      value: "main"
    
    # Image configuration
    - name: image_stream_name
      value: "mistral-24b-full"
    - name: image_tag
      value: "fp-2501"
    
    # Quay configuration
    - name: quay_org
      value: "adrina"
    - name: quay_repo
      value: "private-ai"
    - name: quay_tag
      value: "mistral-24b-full-fp-2501"
    
    # Model Registry (MUST match across all versions!)
    - name: model_name
      value: "Mistral-Small-24B-Instruct"  # Canonical model name (matches HuggingFace)
    - name: version_name
      value: "full-fp16-4gpu"              # Version naming: {variant}-{quant}-{gpu}
    - name: version_description
      value: "Mistral 24B full precision (FP16) - 4x NVIDIA GPU required for optimal performance"
    - name: base_model
      value: "mistralai/Mistral-Small-24B-Instruct-2501"
    - name: quantization
      value: "none"
    - name: gpu_requirement
      value: "4"
  
  workspaces:
    - name: shared-workspace
      volumeClaimTemplate:
        spec:
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: 500Gi  # Critical: Model (48GB) + Buildah layers (48GB duplicate) + OCI image layers (100GB+) + temp build files (50GB+) = ~300GB actual usage. 500Gi provides safety margin.
          storageClassName: gp3-csi
    - name: registry-auth
      secret:
        secretName: internal-registry-private-ai
    - name: quay-auth
      secret:
        secretName: quay-credentials
  
  timeouts:
    pipeline: "4h"      # Total pipeline timeout

