---
apiVersion: tekton.dev/v1
kind: PipelineRun
metadata:
  generateName: tinyllama-test-modelcar-
  namespace: private-ai-demo
  labels:
    tekton.dev/pipeline: modelcar-build-deploy
    app.kubernetes.io/name: modelcar-pipeline
    app.kubernetes.io/component: mlops-pipeline
    app.kubernetes.io/part-of: private-ai-demo
    model: tinyllama-test
  annotations:
    argocd.argoproj.io/sync-wave: "5"
spec:
  pipelineRef:
    name: modelcar-build-deploy
  taskRunTemplate:
    serviceAccountName: model-pipeline-sa
  params:
    # Model source - TinyLlama for quick testing
    - name: hf_repo
      value: "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
    - name: hf_revision
      value: "main"
    
    # Image registry - OpenShift internal
    - name: namespace
      value: "private-ai-demo"
    - name: image_stream_name
      value: "tinyllama-test"
    - name: image_tag
      value: "1.1b-test"
    
    # Quay mirror (optional)
    - name: quay_org
      value: "adrina"
    - name: quay_repo
      value: "private-ai"
    - name: quay_tag
      value: "tinyllama-1.1b-test"
    
    # Model Registry
    - name: model_name
      value: "TinyLlama-Test"
    - name: version_name
      value: "1.1b-test"
    - name: version_description
      value: "TinyLlama 1.1B Chat - Test pipeline to verify authentication fix"
    - name: base_model
      value: "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
    - name: quantization
      value: "none"
    - name: gpu_requirement
      value: "1"
    
  workspaces:
    - name: shared-workspace
      volumeClaimTemplate:
        spec:
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: 20Gi  # TinyLlama is small (~4GB)
    - name: registry-auth
      secret:
        secretName: internal-registry-private-ai  # TEST: Docker registry auth
  
  timeouts:
    pipeline: "30m"  # TinyLlama should complete in ~10-15 minutes
    tasks: "20m"

