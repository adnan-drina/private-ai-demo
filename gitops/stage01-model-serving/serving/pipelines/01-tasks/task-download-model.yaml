apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: download-model-from-hf
  namespace: private-ai-demo
  labels:
    app.kubernetes.io/name: download-model
    app.kubernetes.io/component: pipeline-task
    app.kubernetes.io/part-of: private-ai-demo
  annotations:
    argocd.argoproj.io/sync-wave: "3"
    tekton.dev/pipelines.minVersion: "0.17.0"
    tekton.dev/tags: "model,huggingface,download"
    tekton.dev/displayName: "Download Model from HuggingFace"
spec:
  description: >-
    Downloads a model from HuggingFace Hub to a workspace PVC.
    This is Task 1 of 3 in the ModelCar pipeline, separated for:
    - Better visibility and debugging
    - Reusable downloads (skip if model already exists)
    - Faster retries (don't re-download on build failures)

  params:
    - name: hf_repo
      type: string
      description: HuggingFace repository ID (e.g., mistralai/Mistral-7B-Instruct-v0.2)
    
    - name: hf_revision
      type: string
      description: Git revision (branch, tag, or commit) to download
      default: "main"
    
    - name: target_path
      type: string
      description: Target directory path in workspace
      default: "models"

  workspaces:
    - name: source
      description: Workspace where the model will be downloaded

  results:
    - name: MODEL_SIZE
      description: Size of downloaded model in bytes
    
    - name: DOWNLOAD_TIME
      description: Time taken to download in seconds

  stepTemplate:
    securityContext:
      runAsUser: 0
      runAsGroup: 0

  steps:
    - name: download-model
      image: registry.access.redhat.com/ubi9/python-311:latest
      workingDir: $(workspaces.source.path)
      # Resource requirements for model downloads
      computeResources:
        requests:
          memory: "2Gi"
          cpu: "1"
        limits:
          memory: "4Gi"
          cpu: "2"
      env:
        - name: HF_TOKEN
          valueFrom:
            secretKeyRef:
              name: hf-token
              key: HF_TOKEN
              optional: true
        - name: HF_HOME
          value: $(workspaces.source.path)/.cache
        - name: HF_HUB_CACHE
          value: $(workspaces.source.path)/.cache
      script: |
        #!/bin/bash
        set -e
        
        START_TIME=$(date +%s)
        
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "ğŸ“¥ Downloading Model from HuggingFace"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "Repository:  $(params.hf_repo)"
        echo "Revision:    $(params.hf_revision)"
        echo "Target:      $(workspaces.source.path)/$(params.target_path)"
        echo "HF Token:    ${HF_TOKEN:+<set>}"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        
        # Install HuggingFace Hub library
        echo "ğŸ“¦ Installing dependencies..."
        pip install --quiet --no-cache-dir huggingface-hub
        
        # Create target directory
        mkdir -p "$(params.target_path)"
        
        # Download model using huggingface-cli (simpler than Python script)
        huggingface-cli download \
          "$(params.hf_repo)" \
          --revision "$(params.hf_revision)" \
          --local-dir "$(params.target_path)" \
          --include "*.safetensors" "*.bin" "*.json" "*.txt" "*.model" "*.py" "tokenizer*" "config*" "generation*" "special_tokens*"
        
        # Calculate download time
        END_TIME=$(date +%s)
        DOWNLOAD_TIME=$((END_TIME - START_TIME))
        
        # Calculate model size
        MODEL_SIZE=$(du -sb "$(params.target_path)" | awk '{print $1}')
        
        echo ""
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "âœ… Download Complete!"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "Model size: $(numfmt --to=iec-i --suffix=B $MODEL_SIZE)"
        echo "Time taken: ${DOWNLOAD_TIME}s ($(($DOWNLOAD_TIME / 60))m $(($DOWNLOAD_TIME % 60))s)"
        echo "Location:   $(workspaces.source.path)/$(params.target_path)"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        
        # Save results
        echo -n "$MODEL_SIZE" > $(results.MODEL_SIZE.path)
        echo -n "$DOWNLOAD_TIME" > $(results.DOWNLOAD_TIME.path)
        
        # List downloaded files
        echo ""
        echo "ğŸ“‹ Downloaded files:"
        ls -lh "$(params.target_path)" | head -20

