apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: download-model-from-hf
  namespace: private-ai-demo
  labels:
    app.kubernetes.io/name: download-model
    app.kubernetes.io/component: pipeline-task
    app.kubernetes.io/part-of: private-ai-demo
  annotations:
    argocd.argoproj.io/sync-wave: "3"
    tekton.dev/pipelines.minVersion: "0.17.0"
    tekton.dev/tags: "model,huggingface,download"
    tekton.dev/displayName: "Download Model from HuggingFace"
spec:
  description: >-
    Downloads a model from HuggingFace Hub to a workspace PVC.
    This is Task 1 of 3 in the ModelCar pipeline, separated for:
    - Better visibility and debugging
    - Reusable downloads (skip if model already exists)
    - Faster retries (don't re-download on build failures)

  params:
    - name: hf_repo
      type: string
      description: HuggingFace repository ID (e.g., mistralai/Mistral-7B-Instruct-v0.2)
    
    - name: hf_revision
      type: string
      description: Git revision (branch, tag, or commit) to download
      default: "main"
    
    - name: target_path
      type: string
      description: Target directory path in workspace
      default: "models"

  workspaces:
    - name: source
      description: Workspace where the model will be downloaded

  results:
    - name: MODEL_SIZE
      description: Size of downloaded model in bytes
    
    - name: DOWNLOAD_TIME
      description: Time taken to download in seconds

  stepTemplate:
    securityContext:
      runAsUser: 0
      runAsGroup: 0

  steps:
    - name: download-model
      image: registry.access.redhat.com/ubi9/python-311:latest
      workingDir: $(workspaces.source.path)
      # Resource requirements for model downloads
      computeResources:
        requests:
          memory: "2Gi"
          cpu: "1"
        limits:
          memory: "4Gi"
          cpu: "2"
      env:
        - name: HF_TOKEN
          valueFrom:
            secretKeyRef:
              name: hf-token
              key: HF_TOKEN
              optional: true
        - name: HF_HOME
          value: $(workspaces.source.path)/.cache
        - name: HF_HUB_CACHE
          value: $(workspaces.source.path)/.cache
      script: |
        #!/bin/bash
        set -e
        
        START_TIME=$(date +%s)
        
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "ğŸ“¥ Downloading Model from HuggingFace"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "Repository:  $(params.hf_repo)"
        echo "Revision:    $(params.hf_revision)"
        echo "Target:      $(workspaces.source.path)/$(params.target_path)"
        echo "HF Token:    ${HF_TOKEN:+<set>}"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        
        # Install HuggingFace Hub library
        echo "ğŸ“¦ Installing dependencies..."
        pip install --quiet --no-cache-dir huggingface-hub
        
        # Create target directory
        mkdir -p "$(params.target_path)"
        
        # Create download script
        cat > download.py << 'EOFPY'
from huggingface_hub import snapshot_download
import os
import sys

repo = "$(params.hf_repo)"
revision = "$(params.hf_revision)"
target = "$(params.target_path)"

print(f"\nğŸ“¥ Downloading {repo} (revision: {revision})...")
print(f"   Target: {target}\n")

try:
    # Optimized download with parallel workers
    snapshot_download(
        repo_id=repo,
        revision=revision,
        local_dir=target,
        max_workers=20,              # Parallel downloads (2-3x speedup)
        etag_timeout=5,              # Faster metadata checks
        allow_patterns=[
            "*.safetensors",
            "*.bin",
            "*.json",
            "*.txt",
            "*.model",
            "*.py",
            "tokenizer*",
            "config*",
            "generation*",
            "special_tokens*"
        ]
    )
    print(f"\nâœ… Successfully downloaded {repo}")
except Exception as e:
    print(f"\nâŒ Error downloading model: {e}", file=sys.stderr)
    sys.exit(1)
EOFPY
        
        # Download the model
        python download.py
        
        # Calculate download time
        END_TIME=$(date +%s)
        DOWNLOAD_TIME=$((END_TIME - START_TIME))
        
        # Calculate model size
        MODEL_SIZE=$(du -sb "$(params.target_path)" | awk '{print $1}')
        
        echo ""
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "âœ… Download Complete!"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "Model size: $(numfmt --to=iec-i --suffix=B $MODEL_SIZE)"
        echo "Time taken: ${DOWNLOAD_TIME}s ($(($DOWNLOAD_TIME / 60))m $(($DOWNLOAD_TIME % 60))s)"
        echo "Location:   $(workspaces.source.path)/$(params.target_path)"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        
        # Save results
        echo -n "$MODEL_SIZE" > $(results.MODEL_SIZE.path)
        echo -n "$DOWNLOAD_TIME" > $(results.DOWNLOAD_TIME.path)
        
        # List downloaded files
        echo ""
        echo "ğŸ“‹ Downloaded files:"
        ls -lh "$(params.target_path)" | head -20

