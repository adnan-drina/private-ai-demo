apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: prepare-modelcar-context
  namespace: private-ai-demo
  labels:
    app.kubernetes.io/name: prepare-modelcar
    app.kubernetes.io/component: pipeline-task
    app.kubernetes.io/part-of: private-ai-demo
  annotations:
    argocd.argoproj.io/sync-wave: "3"
    tekton.dev/pipelines.minVersion: "0.17.0"
    tekton.dev/tags: "model,huggingface"
    tekton.dev/displayName: "Prepare ModelCar Build Context"
spec:
  description: >-
    This task prepares the build context for a ModelCar container image.
    It creates a Containerfile that downloads a model from HuggingFace
    during the build process and packages it into a minimal container image.

  params:
    - name: hf_repo
      type: string
      description: HuggingFace repository ID (e.g., mistralai/Mistral-7B-Instruct-v0.2)
    
    - name: hf_revision
      type: string
      description: Git revision (branch, tag, or commit) to download
      default: "main"

  workspaces:
    - name: source
      description: Workspace where the build context will be created

  steps:
    - name: create-build-context
      image: registry.access.redhat.com/ubi9/python-311:latest
      workingDir: $(workspaces.source.path)
      env:
        - name: HF_TOKEN
          valueFrom:
            secretKeyRef:
              name: huggingface-token
              key: token
              optional: true
      script: |
        #!/bin/bash
        set -e
        
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "ðŸ“¦ Preparing ModelCar Build Context"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "HuggingFace Repo: $(params.hf_repo)"
        echo "Revision:         $(params.hf_revision)"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        
        # Create download script
        cat > download_model.py << 'EOF'
from huggingface_hub import snapshot_download
import os
import sys

repo = os.environ.get("HF_REPO")
revision = os.environ.get("HF_REVISION", "main")
target = "/models"

print(f"Downloading {repo} (revision: {revision})...")
os.makedirs(target, exist_ok=True)

try:
    snapshot_download(
        repo_id=repo,
        revision=revision,
        local_dir=target,
        local_dir_use_symlinks=False,
        allow_patterns=[
            "*.safetensors",
            "*.bin",
            "*.json",
            "*.txt",
            "*.model",
            "*.py",
            "tokenizer*",
            "config*",
            "generation*",
            "special_tokens*"
        ]
    )
    print(f"âœ… Successfully downloaded {repo}")
except Exception as e:
    print(f"âŒ Error downloading model: {e}", file=sys.stderr)
    sys.exit(1)
EOF
        
        # Create Containerfile using Red Hat UBI base images
        cat > Containerfile << 'EOF'
# Stage 1: Download the model from HuggingFace
FROM registry.access.redhat.com/ubi9/python-311:latest AS downloader

USER 0

# Install HuggingFace Hub library
RUN pip install --no-cache-dir huggingface-hub

# Copy download script
COPY download_model.py /download_model.py

# Set build arguments and environment variables
ARG HF_REPO
ARG HF_REVISION=main
ENV HF_REPO=${HF_REPO}
ENV HF_REVISION=${HF_REVISION}
ENV HF_HOME=/tmp/hf
ENV HF_HUB_CACHE=/tmp/hf

# Download the model
RUN python /download_model.py

# Stage 2: Create minimal runtime image with model
FROM registry.access.redhat.com/ubi9/ubi-micro:9.5

# Copy model files from downloader stage
COPY --from=downloader /models /models

# Set ownership and permissions
USER 1001

# Labels for OpenShift
LABEL name="modelcar" \
      vendor="Red Hat" \
      version="1.0" \
      summary="ModelCar container with HuggingFace model" \
      description="This image contains an AI model packaged as a ModelCar for use with vLLM"

# Default command (not used in vLLM but good practice)
CMD ["/bin/sh", "-c", "echo 'ModelCar ready. Model files at /models'"]
EOF
        
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "âœ… Build context prepared successfully"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        ls -la
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

