apiVersion: grafana.integreatly.org/v1beta1
kind: GrafanaDashboard
metadata:
  name: trustyai-eval-results
  namespace: private-ai-demo
  labels:
    app: grafana
spec:
  instanceSelector:
    matchLabels:
      dashboards: grafana
  json: |
    {
      "title": "TrustyAI Model Quality - Evaluation Results",
      "uid": "trustyai-eval-results",
      "timezone": "browser",
      "schemaVersion": 38,
      "version": 2,
      "refresh": "30s",
      "time": {
        "from": "now-24h",
        "to": "now"
      },
      "tags": ["trustyai", "evaluation", "model-quality", "llm"],
      "panels": [
        {
          "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0},
          "id": 1,
          "title": "Latest Accuracy by Task",
          "type": "table",
          "datasource": {"type": "prometheus", "uid": "otel-prometheus"},
          "targets": [
            {
              "refId": "A",
              "expr": "lm_eval_accuracy * 100",
              "instant": true,
              "legendFormat": "{{task}} Â· {{model}}"
            }
          ],
          "transformations": [
            {"id": "labelsToFields", "options": {"valueLabel": "Accuracy (%)"}},
            {
              "id": "organize",
              "options": {
                "indexByName": {
                  "Time": 0,
                  "task": 1,
                  "model": 2,
                  "Accuracy (%)": 3
                },
                "renameByName": {"task": "Task", "model": "Model", "Accuracy (%)": "Accuracy (%)"}
              }
            }
          ],
          "options": {
            "showHeader": true,
            "sortBy": [{"displayName": "Task", "desc": false}]
          },
          "fieldConfig": {
            "defaults": {
              "unit": "percent",
              "decimals": 1
            }
          }
        },
        {
          "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0},
          "id": 2,
          "title": "Samples Evaluated",
          "type": "table",
          "datasource": {"type": "prometheus", "uid": "otel-prometheus"},
          "targets": [
            {
              "refId": "A",
              "expr": "lm_eval_samples_evaluated",
              "instant": true,
              "legendFormat": "{{task}} Â· {{model}}"
            }
          ],
          "transformations": [
            {"id": "labelsToFields", "options": {"valueLabel": "Samples"}},
            {
              "id": "organize",
              "options": {
                "indexByName": {"Time": 0, "task": 1, "model": 2, "Samples": 3},
                "renameByName": {"task": "Task", "model": "Model", "Samples": "Samples"}
              }
            }
          ],
          "options": {
            "showHeader": true,
            "sortBy": [{"displayName": "Task", "desc": false}]
          },
          "fieldConfig": {"defaults": {"unit": "none", "decimals": 0}}
        },
        {
          "gridPos": {"h": 6, "w": 6, "x": 0, "y": 8},
          "id": 3,
          "title": "ARC-Easy Accuracy Delta (Quantized - Full)",
          "type": "stat",
          "datasource": {"type": "prometheus", "uid": "otel-prometheus"},
          "targets": [
            {
              "refId": "A",
              "expr": "(lm_eval_accuracy{model=\"quantized\",task=\"arc_easy\"} - lm_eval_accuracy{model=\"full\",task=\"arc_easy\"}) * 100",
              "instant": true
            }
          ],
          "fieldConfig": {
            "defaults": {
              "unit": "percent",
              "decimals": 1,
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {"value": -10, "color": "red"},
                  {"value": -3, "color": "orange"},
                  {"value": -1, "color": "green"},
                  {"value": 1, "color": "orange"},
                  {"value": 3, "color": "red"}
                ]
              }
            }
          },
          "options": {
            "colorMode": "value",
            "graphMode": "none",
            "reduceOptions": {"calcs": ["lastNotNull"], "values": false},
            "textMode": "value_and_name"
          }
        },
        {
          "gridPos": {"h": 6, "w": 6, "x": 6, "y": 8},
          "id": 4,
          "title": "HellaSwag Accuracy Delta (Quantized - Full)",
          "type": "stat",
          "datasource": {"type": "prometheus", "uid": "otel-prometheus"},
          "targets": [
            {
              "refId": "A",
              "expr": "(lm_eval_accuracy{model=\"quantized\",task=\"hellaswag\"} - lm_eval_accuracy{model=\"full\",task=\"hellaswag\"}) * 100",
              "instant": true
            }
          ],
          "fieldConfig": {
            "defaults": {
              "unit": "percent",
              "decimals": 1,
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {"value": -10, "color": "red"},
                  {"value": -3, "color": "orange"},
                  {"value": -1, "color": "green"},
                  {"value": 1, "color": "orange"},
                  {"value": 3, "color": "red"}
                ]
              }
            }
          },
          "options": {
            "colorMode": "value",
            "graphMode": "none",
            "reduceOptions": {"calcs": ["lastNotNull"], "values": false},
            "textMode": "value_and_name"
          }
        },
        {
          "gridPos": {"h": 6, "w": 6, "x": 12, "y": 8},
          "id": 5,
          "title": "Evaluation Metrics Reported",
          "type": "stat",
          "datasource": {"type": "prometheus", "uid": "otel-prometheus"},
          "targets": [
            {
              "refId": "A",
              "expr": "count(lm_eval_accuracy)",
              "instant": true
            }
          ],
          "fieldConfig": {
            "defaults": {"unit": "short", "thresholds": {"mode": "absolute", "steps": [{"value": 0, "color": "red"}, {"value": 2, "color": "yellow"}, {"value": 4, "color": "green"}]}}
          },
          "options": {"reduceOptions": {"calcs": ["lastNotNull"], "values": false}, "textMode": "value_and_name"}
        },
        {
          "gridPos": {"h": 6, "w": 6, "x": 18, "y": 8},
          "id": 6,
          "title": "Documentation",
          "type": "text",
          "options": {
            "mode": "markdown",
            "content": "### ðŸ“š References\n- [OpenShift AI: Managing and monitoring models](https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/2.25/html-single/managing_and_monitoring_models/index)\n- TrustyAI LMEvalJobs emit Prometheus metrics `lm_eval_*` consumed here.\n- Update pipeline or job manifests to add new benchmark runs."
          }
        },
        {
          "gridPos": {"h": 8, "w": 6, "x": 0, "y": 14},
          "id": 7,
          "title": "ARC-Easy Accuracy (Full Precision)",
          "type": "gauge",
          "datasource": {"type": "prometheus", "uid": "otel-prometheus"},
          "targets": [
            {"refId": "A", "expr": "lm_eval_accuracy{model=\"full\",task=\"arc_easy\"} * 100", "instant": true}
          ],
          "fieldConfig": {
            "defaults": {
              "unit": "percent",
              "min": 0,
              "max": 100,
              "decimals": 1,
              "thresholds": {
                "mode": "absolute",
                "steps": [{"value": 0, "color": "red"}, {"value": 70, "color": "orange"}, {"value": 85, "color": "green"}]
              }
            }
          },
          "options": {"showThresholdMarkers": true}
        },
        {
          "gridPos": {"h": 8, "w": 6, "x": 6, "y": 14},
          "id": 8,
          "title": "ARC-Easy Accuracy (Quantized)",
          "type": "gauge",
          "datasource": {"type": "prometheus", "uid": "otel-prometheus"},
          "targets": [
            {"refId": "A", "expr": "lm_eval_accuracy{model=\"quantized\",task=\"arc_easy\"} * 100", "instant": true}
          ],
          "fieldConfig": {
            "defaults": {
              "unit": "percent",
              "min": 0,
              "max": 100,
              "decimals": 1,
              "thresholds": {
                "mode": "absolute",
                "steps": [{"value": 0, "color": "red"}, {"value": 70, "color": "orange"}, {"value": 85, "color": "green"}]
              }
            }
          },
          "options": {"showThresholdMarkers": true}
        },
        {
          "gridPos": {"h": 8, "w": 12, "x": 12, "y": 14},
          "id": 9,
          "title": "ARC-Easy Accuracy Trend",
          "type": "timeseries",
          "datasource": {"type": "prometheus", "uid": "otel-prometheus"},
          "targets": [
            {"refId": "A", "expr": "lm_eval_accuracy{task=\"arc_easy\"} * 100", "legendFormat": "{{model}}"}
          ],
          "fieldConfig": {"defaults": {"unit": "percent", "decimals": 1, "custom": {"drawStyle": "line", "fillOpacity": 20}}},
          "options": {"legend": {"showLegend": true, "placement": "bottom"}}
        },
        {
          "gridPos": {"h": 8, "w": 6, "x": 0, "y": 22},
          "id": 10,
          "title": "HellaSwag Accuracy (Full Precision)",
          "type": "gauge",
          "datasource": {"type": "prometheus", "uid": "otel-prometheus"},
          "targets": [
            {"refId": "A", "expr": "lm_eval_accuracy{model=\"full\",task=\"hellaswag\"} * 100", "instant": true}
          ],
          "fieldConfig": {
            "defaults": {
              "unit": "percent",
              "min": 0,
              "max": 100,
              "decimals": 1,
              "thresholds": {
                "mode": "absolute",
                "steps": [{"value": 0, "color": "red"}, {"value": 60, "color": "orange"}, {"value": 70, "color": "green"}]
              }
            }
          },
          "options": {"showThresholdMarkers": true}
        },
        {
          "gridPos": {"h": 8, "w": 6, "x": 6, "y": 22},
          "id": 11,
          "title": "HellaSwag Accuracy (Quantized)",
          "type": "gauge",
          "datasource": {"type": "prometheus", "uid": "otel-prometheus"},
          "targets": [
            {"refId": "A", "expr": "lm_eval_accuracy{model=\"quantized\",task=\"hellaswag\"} * 100", "instant": true}
          ],
          "fieldConfig": {
            "defaults": {
              "unit": "percent",
              "min": 0,
              "max": 100,
              "decimals": 1,
              "thresholds": {
                "mode": "absolute",
                "steps": [{"value": 0, "color": "red"}, {"value": 60, "color": "orange"}, {"value": 70, "color": "green"}]
              }
            }
          },
          "options": {"showThresholdMarkers": true}
        },
        {
          "gridPos": {"h": 8, "w": 12, "x": 12, "y": 22},
          "id": 12,
          "title": "HellaSwag Accuracy Trend",
          "type": "timeseries",
          "datasource": {"type": "prometheus", "uid": "otel-prometheus"},
          "targets": [
            {"refId": "A", "expr": "lm_eval_accuracy{task=\"hellaswag\"} * 100", "legendFormat": "{{model}}"}
          ],
          "fieldConfig": {"defaults": {"unit": "percent", "decimals": 1, "custom": {"drawStyle": "line", "fillOpacity": 20}}},
          "options": {"legend": {"showLegend": true, "placement": "bottom"}}
        }
      ]
    }

