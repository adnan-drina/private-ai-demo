---
apiVersion: infrastructure.opendatahub.io/v1alpha1
kind: HardwareProfile
metadata:
  name: nvidia-l4-4gpu
  namespace: redhat-ods-applications
  labels:
    app.kubernetes.io/name: nvidia-l4-4gpu
    app.kubernetes.io/component: hardware-profile
    app.kubernetes.io/part-of: private-ai-demo
  annotations:
    argocd.argoproj.io/sync-wave: "1"
    opendatahub.io/description: "NVIDIA L4 GPU - 4 GPUs for full precision large models"
spec:
  # Array of hardware identifiers (GPUs in this case)
  identifiers:
    - identifier: "nvidia.com/gpu"
      resourceType: "Accelerator"
      displayName: "NVIDIA L4 GPU"
      minCount: 4
      defaultCount: 4
      maxCount: 4
  
  # Scheduling configuration for node-based placement
  scheduling:
    type: "Node"  # Direct node scheduling (not queue-based)
    node:
      # Select g6.12xlarge instances (4x L4 GPU)
      nodeSelector:
        node.kubernetes.io/instance-type: "g6.12xlarge"
      
      # Tolerations for GPU-tainted nodes
      tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"
