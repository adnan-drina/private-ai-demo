{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ACME LithoOps Copilot - RAG Demo\n",
        "\n",
        "Production-ready RAG system for ACME lithography operations.\n",
        "\n",
        "**Use Case**: Technical support for L-900 EUV tools and PX-7 product."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eedc8f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q llama-stack-client openai fire\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates the ACME LithoOps Copilot using:\n",
        "- **Llama Stack** for RAG orchestration\n",
        "- **Milvus** for vector storage (IBM Granite 768-d embeddings)\n",
        "- **Mistral-24B-Quantized** for answer synthesis\n",
        "- **6 ACME documents** (SOPs, SPCs, FMEAs, Playbooks, Recipes, Reports)\n",
        "\n",
        "**Comparison**: Baseline (no RAG) vs RAG (with document retrieval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65e83a47",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "from llama_stack_client import LlamaStackClient, Agent, AgentEventLogger\n",
        "from openai import OpenAI\n",
        "import uuid\n",
        "\n",
        "# Configuration\n",
        "LLAMASTACK_URL = \"${LLAMASTACK_URL}\"\n",
        "VLLM_URL = \"${VLLM_URL}\"\n",
        "MODEL_ID = \"mistral-24b-quantized\"\n",
        "\n",
        "# Initialize clients\n",
        "stack_client = LlamaStackClient(base_url=LLAMASTACK_URL)\n",
        "vllm_client = OpenAI(base_url=VLLM_URL, api_key=\"dummy\")\n",
        "\n",
        "print(\"\u2705 Imports complete\")\n",
        "print(f\"\ud83d\udce1 Llama Stack: {LLAMASTACK_URL}\")\n",
        "print(f\"\ud83e\udd16 vLLM: {VLLM_URL}\")\n",
        "print(f\"\ud83e\udd16 Model: {MODEL_ID}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ACME Test Questions\n",
        "QUESTIONS = {\n",
        "    \"limits\": \"What are the dose UCL and overlay UCL limits for PX-7 product on M1 layer?\",\n",
        "    \"limit_check\": \"Is a measured overlay of 3.8 nm within specification for PX-7 M1 layer?\",\n",
        "    \"calibration\": \"What is the DFO calibration procedure for the L-900 EUV tool?\",\n",
        "    \"troubleshooting\": \"The L-900 tool is showing overlay drift >4 nm. What troubleshooting steps should I follow?\"\n",
        "}\n",
        "\n",
        "# Use limit_check for main demo\n",
        "DEMO_QUESTION = QUESTIONS[\"limit_check\"]\n",
        "\n",
        "print(\"\ud83d\udccb ACME Test Questions:\")\n",
        "for key, question in QUESTIONS.items():\n",
        "    print(f\"\\n{key.upper()}:\")\n",
        "    print(f\"  {question}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scenario 1: Baseline (No RAG)\n",
        "\n",
        "First, let's ask the model **without RAG**. The model will respond based only on its training data (generic lithography knowledge)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"BASELINE RESPONSE (No RAG - Direct vLLM)\")\n",
        "print(\"=\"*70)\n",
        "print()\n",
        "print(f\"Question: {DEMO_QUESTION}\")\n",
        "print()\n",
        "\n",
        "try:\n",
        "    response = vllm_client.chat.completions.create(\n",
        "        model=MODEL_ID,\n",
        "        messages=[{\"role\": \"user\", \"content\": DEMO_QUESTION}],\n",
        "        max_tokens=500\n",
        "    )\n",
        "    \n",
        "    baseline_answer = response.choices[0].message.content\n",
        "    print(baseline_answer)\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"\u274c Error: {e}\")\n",
        "    baseline_answer = \"Error\"\n",
        "\n",
        "print()\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scenario 2: RAG (With Document Retrieval)\n",
        "\n",
        "Now let's use **RAG with Llama Stack Agent**. The system will:\n",
        "1. Retrieve relevant chunks from ACME documents\n",
        "2. Use those chunks to generate a grounded answer\n",
        "3. Include precise citations [Doc, \u00a7section, p.X]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"RAG RESPONSE (With ACME Documents - Llama Stack Agent)\")\n",
        "print(\"=\"*70)\n",
        "print()\n",
        "print(f\"Question: {DEMO_QUESTION}\")\n",
        "print()\n",
        "\n",
        "try:\n",
        "    # Initialize Llama Stack client\n",
        "    llama_client = LlamaStackClient(base_url=LLAMASTACK_URL)\n",
        "    \n",
        "    # Create RAG agent with ACME-specific instructions\n",
        "    rag_agent = Agent(\n",
        "        llama_client,\n",
        "        model=MODEL_ID,\n",
        "        instructions=(\n",
        "            \"You are an ACME LithoOps technical assistant. \"\n",
        "            \"Answer questions using ONLY information from the retrieved ACME documents. \"\n",
        "            \"\\n\"\n",
        "            \"For limit queries:\\n\"\n",
        "            \"- Provide the specific numeric limit with units\\n\"\n",
        "            \"- Compare measured value against limit\\n\"\n",
        "            \"- State clearly: IN SPEC or OUT OF SPEC\\n\"\n",
        "            \"- Include troubleshooting actions if out of spec\\n\"\n",
        "            \"\\n\"\n",
        "            \"For troubleshooting queries:\\n\"\n",
        "            \"- Start with immediate diagnostic actions\\n\"\n",
        "            \"- List steps as bullets\\n\"\n",
        "            \"- Provide escalation path\\n\"\n",
        "            \"\\n\"\n",
        "            \"For procedural queries:\\n\"\n",
        "            \"- Summarize the procedure\\n\"\n",
        "            \"- List key steps\\n\"\n",
        "            \"- Note prerequisites\\n\"\n",
        "            \"\\n\"\n",
        "            \"Citations: Include [Doc, \u00a7section, p.X] for every claim. \"\n",
        "            \"If information is not in ACME sources, say 'Not found in ACME sources.'\"\n",
        "        ),\n",
        "        tools=[\n",
        "            {\n",
        "                \"name\": \"builtin::rag/knowledge_search\",\n",
        "                \"args\": {\"vector_db_ids\": [\"rag_documents\"]},\n",
        "            }\n",
        "        ],\n",
        "    )\n",
        "    \n",
        "    print(\"\u2705 Agent created\")\n",
        "    print()\n",
        "    \n",
        "    # Create session\n",
        "    session_id = rag_agent.create_session(session_name=f\"acme-demo-{uuid.uuid4().hex[:8]}\")\n",
        "    print(f\"\u2705 Session created: {session_id}\")\n",
        "    print()\n",
        "    \n",
        "    # Query with RAG\n",
        "    response = rag_agent.create_turn(\n",
        "        messages=[{\"role\": \"user\", \"content\": DEMO_QUESTION}],\n",
        "        session_id=session_id,\n",
        "        stream=True,\n",
        "    )\n",
        "    \n",
        "    # Capture and log response\n",
        "    rag_answer = \"\"\n",
        "    for log in AgentEventLogger().log(response):\n",
        "        log.print()\n",
        "        if hasattr(log, 'content') and log.content:\n",
        "            rag_answer += log.content\n",
        "    \n",
        "    print()\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\u274c Error: {e}\")\n",
        "    print(\"\\n\u2139\ufe0f  Note: RAG requires ACME documents to be ingested into Milvus.\")\n",
        "    print(\"   Run the Tekton pipeline first: pipeline-acme-ingestion\")\n",
        "    rag_answer = None\n",
        "\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Side-by-Side Comparison\n",
        "\n",
        "Let's compare the two approaches:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if rag_answer:\n",
        "    # Format for side-by-side display\n",
        "    def format_column(text, width=70):\n",
        "        lines = []\n",
        "        for line in text.split('\\n'):\n",
        "            if len(line) <= width:\n",
        "                lines.append(line.ljust(width))\n",
        "            else:\n",
        "                words = line.split()\n",
        "                current_line = \"\"\n",
        "                for word in words:\n",
        "                    if len(current_line) + len(word) + 1 <= width:\n",
        "                        current_line += (\" \" if current_line else \"\") + word\n",
        "                    else:\n",
        "                        lines.append(current_line.ljust(width))\n",
        "                        current_line = word\n",
        "                if current_line:\n",
        "                    lines.append(current_line.ljust(width))\n",
        "        return lines\n",
        "    \n",
        "    baseline_lines = format_column(baseline_answer)\n",
        "    rag_lines = format_column(rag_answer)\n",
        "    \n",
        "    # Pad to same length\n",
        "    max_len = max(len(baseline_lines), len(rag_lines))\n",
        "    baseline_lines += [\"\".ljust(70)] * (max_len - len(baseline_lines))\n",
        "    rag_lines += [\"\".ljust(70)] * (max_len - len(rag_lines))\n",
        "    \n",
        "    print(\"=\"*140)\n",
        "    print(f\"{'BASELINE (No RAG)'.center(70)} | {'RAG (With ACME Documents)'.center(70)}\")\n",
        "    print(\"=\"*140)\n",
        "    \n",
        "    for baseline, rag in zip(baseline_lines, rag_lines):\n",
        "        print(f\"{baseline} | {rag}\")\n",
        "    \n",
        "    print(\"=\"*140)\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f  RAG answer not available - ACME documents may need to be ingested\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test All ACME Questions\n",
        "\n",
        "Let's test all question types to see RAG's performance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_question_with_rag(question, question_type):\n",
        "    \"\"\"Test a question with RAG\"\"\"\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"TEST: {question_type.upper()}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"\\nQuestion: {question}\")\n",
        "    print()\n",
        "    \n",
        "    try:\n",
        "        # Create new session\n",
        "        new_session_id = rag_agent.create_session(session_name=f\"test-{question_type}-{uuid.uuid4().hex[:8]}\")\n",
        "        \n",
        "        # Query\n",
        "        response = rag_agent.create_turn(\n",
        "            messages=[{\"role\": \"user\", \"content\": question}],\n",
        "            session_id=new_session_id,\n",
        "            stream=True,\n",
        "        )\n",
        "        \n",
        "        # Capture response\n",
        "        answer = \"\"\n",
        "        for log in AgentEventLogger().log(response):\n",
        "            log.print()\n",
        "            if hasattr(log, 'content') and log.content:\n",
        "                answer += log.content\n",
        "        \n",
        "        print()\n",
        "        return answer\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\u274c Error: {e}\")\n",
        "        return None\n",
        "\n",
        "# Test all questions if agent is available\n",
        "if rag_answer and 'rag_agent' in locals():\n",
        "    results = {}\n",
        "    for q_type, question in QUESTIONS.items():\n",
        "        if q_type != \"limit_check\":  # Already tested\n",
        "            results[q_type] = test_question_with_rag(question, q_type)\n",
        "    \n",
        "    print(\"\\n\u2705 All questions tested!\")\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f  Skipping additional tests - agent not available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "The ACME LithoOps Copilot demonstrates:\n",
        "\n",
        "\u2705 **Accurate Limit Checking**: Compares measured values against specs with numeric precision\n",
        "\n",
        "\u2705 **Grounded Troubleshooting**: Provides action-oriented steps from official playbooks\n",
        "\n",
        "\u2705 **Precise Citations**: Every claim is backed by [Doc, \u00a7section, p.X] references\n",
        "\n",
        "\u2705 **Manufacturing Context**: Understands tools (L-900), products (PX-7), and layers (M1)\n",
        "\n",
        "\u2705 **Multi-Document Synthesis**: Integrates SOPs, SPCs, FMEAs, and Playbooks\n",
        "\n",
        "**Next Steps**: Run evaluation harness to test all 10 questions systematically."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}