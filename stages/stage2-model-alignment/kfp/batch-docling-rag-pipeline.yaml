# PIPELINE DEFINITION
# Name: data-processing-and-insertion
# Description: RAG Ingestion Pipeline v1.0.2 - Refactored with modular components. Optimized server-side embeddings via LlamaStack Vector IO.
# Inputs:
#    cache_buster: str [Default: '']
#    chunk_size: int [Default: 512.0]
#    docling_url: str [Default: 'http://docling-service.private-ai-demo.svc:5001']
#    llamastack_url: str [Default: 'http://llama-stack-service.private-ai-demo.svc:8321']
#    minio_creds_b64: str [Default: '']
#    minio_endpoint: str [Default: 'minio.model-storage.svc:9000']
#    num_splits: int [Default: 2.0]
#    s3_prefix: str [Default: 's3://llama-files/sample/']
#    s3_secret_mount_path: str [Default: '/mnt/secrets']
#    vector_db_id: str [Default: 'acme_corporate']
components:
  comp-chunk-markdown:
    executorLabel: exec-chunk-markdown
    inputDefinitions:
      artifacts:
        markdown_file:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        chunk_size:
          parameterType: NUMBER_INTEGER
    outputDefinitions:
      artifacts:
        output_chunks:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-download-from-s3:
    executorLabel: exec-download-from-s3
    inputDefinitions:
      parameters:
        input_uri:
          parameterType: STRING
        minio_creds_b64:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        minio_endpoint:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        s3_secret_mount_path:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        output_file:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-for-loop-1:
    dag:
      tasks:
        for-loop-2:
          componentRef:
            name: comp-for-loop-2
          inputs:
            parameters:
              pipelinechannel--chunk_size:
                componentInputParameter: pipelinechannel--chunk_size
              pipelinechannel--docling_url:
                componentInputParameter: pipelinechannel--docling_url
              pipelinechannel--llamastack_url:
                componentInputParameter: pipelinechannel--llamastack_url
              pipelinechannel--minio_creds_b64:
                componentInputParameter: pipelinechannel--minio_creds_b64
              pipelinechannel--minio_endpoint:
                componentInputParameter: pipelinechannel--minio_endpoint
              pipelinechannel--s3_secret_mount_path:
                componentInputParameter: pipelinechannel--s3_secret_mount_path
              pipelinechannel--split-pdf-list-Output-loop-item:
                componentInputParameter: pipelinechannel--split-pdf-list-Output-loop-item
              pipelinechannel--vector_db_id:
                componentInputParameter: pipelinechannel--vector_db_id
          iteratorPolicy:
            parallelismLimit: 1
          parameterIterator:
            itemInput: pipelinechannel--split-pdf-list-Output-loop-item-loop-item
            items:
              inputParameter: pipelinechannel--split-pdf-list-Output-loop-item
          taskInfo:
            name: process-each-pdf
    inputDefinitions:
      parameters:
        pipelinechannel--chunk_size:
          parameterType: NUMBER_INTEGER
        pipelinechannel--docling_url:
          parameterType: STRING
        pipelinechannel--llamastack_url:
          parameterType: STRING
        pipelinechannel--minio_creds_b64:
          parameterType: STRING
        pipelinechannel--minio_endpoint:
          parameterType: STRING
        pipelinechannel--s3_secret_mount_path:
          parameterType: STRING
        pipelinechannel--split-pdf-list-Output:
          parameterType: LIST
        pipelinechannel--split-pdf-list-Output-loop-item:
          parameterType: LIST
        pipelinechannel--vector_db_id:
          parameterType: STRING
  comp-for-loop-2:
    dag:
      tasks:
        chunk-markdown:
          cachingOptions: {}
          componentRef:
            name: comp-chunk-markdown
          dependentTasks:
          - process-with-docling
          inputs:
            artifacts:
              markdown_file:
                taskOutputArtifact:
                  outputArtifactKey: output_markdown
                  producerTask: process-with-docling
            parameters:
              chunk_size:
                componentInputParameter: pipelinechannel--chunk_size
          taskInfo:
            name: chunk-markdown
        download-from-s3:
          cachingOptions: {}
          componentRef:
            name: comp-download-from-s3
          inputs:
            parameters:
              input_uri:
                componentInputParameter: pipelinechannel--split-pdf-list-Output-loop-item-loop-item
              minio_creds_b64:
                componentInputParameter: pipelinechannel--minio_creds_b64
              minio_endpoint:
                componentInputParameter: pipelinechannel--minio_endpoint
              s3_secret_mount_path:
                componentInputParameter: pipelinechannel--s3_secret_mount_path
          taskInfo:
            name: download-from-s3
        insert-via-llamastack:
          cachingOptions: {}
          componentRef:
            name: comp-insert-via-llamastack
          dependentTasks:
          - chunk-markdown
          inputs:
            artifacts:
              chunks_file:
                taskOutputArtifact:
                  outputArtifactKey: output_chunks
                  producerTask: chunk-markdown
            parameters:
              input_uri:
                componentInputParameter: pipelinechannel--split-pdf-list-Output-loop-item-loop-item
              llamastack_url:
                componentInputParameter: pipelinechannel--llamastack_url
              vector_db_id:
                componentInputParameter: pipelinechannel--vector_db_id
          retryPolicy:
            backoffDuration: 0s
            backoffFactor: 2.0
            backoffMaxDuration: 3600s
          taskInfo:
            name: insert-via-llamastack
        process-with-docling:
          cachingOptions: {}
          componentRef:
            name: comp-process-with-docling
          dependentTasks:
          - download-from-s3
          inputs:
            artifacts:
              input_file:
                taskOutputArtifact:
                  outputArtifactKey: output_file
                  producerTask: download-from-s3
            parameters:
              docling_url:
                componentInputParameter: pipelinechannel--docling_url
          taskInfo:
            name: process-with-docling
    inputDefinitions:
      parameters:
        pipelinechannel--chunk_size:
          parameterType: NUMBER_INTEGER
        pipelinechannel--docling_url:
          parameterType: STRING
        pipelinechannel--llamastack_url:
          parameterType: STRING
        pipelinechannel--minio_creds_b64:
          parameterType: STRING
        pipelinechannel--minio_endpoint:
          parameterType: STRING
        pipelinechannel--s3_secret_mount_path:
          parameterType: STRING
        pipelinechannel--split-pdf-list-Output-loop-item:
          parameterType: LIST
        pipelinechannel--split-pdf-list-Output-loop-item-loop-item:
          parameterType: STRING
        pipelinechannel--vector_db_id:
          parameterType: STRING
  comp-insert-via-llamastack:
    executorLabel: exec-insert-via-llamastack
    inputDefinitions:
      artifacts:
        chunks_file:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        input_uri:
          parameterType: STRING
        llamastack_url:
          parameterType: STRING
        vector_db_id:
          parameterType: STRING
    outputDefinitions:
      parameters:
        Output:
          parameterType: STRUCT
  comp-list-pdfs-in-s3:
    executorLabel: exec-list-pdfs-in-s3
    inputDefinitions:
      parameters:
        minio_creds_b64:
          defaultValue: ''
          description: Optional fallback credentials in base64 ("access:secret")
          isOptional: true
          parameterType: STRING
        minio_endpoint:
          defaultValue: ''
          description: Optional fallback endpoint (used if secret not mounted)
          isOptional: true
          parameterType: STRING
        s3_prefix:
          description: S3 path prefix (e.g. "s3://llama-files/scenario2-acme/")
          parameterType: STRING
        s3_secret_mount_path:
          defaultValue: /mnt/secrets
          description: Filesystem path where S3 credentials are mounted
          isOptional: true
          parameterType: STRING
    outputDefinitions:
      parameters:
        Output:
          parameterType: LIST
  comp-process-with-docling:
    executorLabel: exec-process-with-docling
    inputDefinitions:
      artifacts:
        input_file:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        docling_url:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        output_markdown:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-split-pdf-list:
    executorLabel: exec-split-pdf-list
    inputDefinitions:
      parameters:
        num_splits:
          defaultValue: 2.0
          description: Desired number of splits (defaults to 2).
          isOptional: true
          parameterType: NUMBER_INTEGER
        pdf_uris:
          description: List of full S3 URIs to process.
          parameterType: LIST
    outputDefinitions:
      parameters:
        Output:
          parameterType: LIST
defaultPipelineRoot: s3://kfp-artifacts/
deploymentSpec:
  executors:
    exec-chunk-markdown:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - chunk_markdown
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.14.6'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef chunk_markdown(\n    markdown_file: Input[Dataset],\n    chunk_size:\
          \ int,\n    output_chunks: Output[Dataset]\n):\n    \"\"\"\n    Chunk markdown\
          \ document for RAG ingestion\n\n    NOTE: Embeddings are computed server-side\
          \ by LlamaStack, not by this step.\n    This is purely chunking - no HTTP\
          \ calls, faster and cheaper.\n    \"\"\"\n    import json\n\n    print(f\"\
          Chunking markdown document...\")\n\n    # Read markdown\n    with open(markdown_file.path,\
          \ \"r\") as f:\n        content = f.read()\n\n    # Smart chunking with\
          \ size limit (Milvus dynamic field limit is 65536 chars)\n    # Use chunk_size\
          \ parameter but enforce Milvus limit\n    MAX_CHUNK_SIZE = 60000  # Absolute\
          \ ceiling enforced by Milvus dynamic field limit\n    effective_chunk_size\
          \ = min(max(chunk_size, 1), MAX_CHUNK_SIZE)\n\n    print(f\"Chunking with\
          \ max size: {effective_chunk_size} chars\")\n\n    # Split by paragraphs\
          \ first\n    paragraphs = [p.strip() for p in content.split(\"\\n\\n\")\
          \ if p.strip()]\n\n    # Combine paragraphs into chunks respecting size\
          \ limit\n    chunks = []\n    current_chunk = []\n    current_length = 0\n\
          \n    for para in paragraphs:\n        para_len = len(para)\n\n        #\
          \ If single paragraph exceeds limit, split it\n        if para_len > effective_chunk_size:\n\
          \            # Add current chunk if any\n            if current_chunk:\n\
          \                chunks.append(\"\\n\\n\".join(current_chunk))\n       \
          \         current_chunk = []\n                current_length = 0\n\n   \
          \         # Split large paragraph by sentences\n            sentences =\
          \ para.split(\". \")\n            temp_chunk = []\n            temp_len\
          \ = 0\n\n            for sent in sentences:\n                sent_len =\
          \ len(sent) + 2  # +2 for \". \"\n                if temp_len + sent_len\
          \ > effective_chunk_size:\n                    if temp_chunk:\n        \
          \                chunks.append(\". \".join(temp_chunk) + \".\")\n      \
          \              temp_chunk = [sent]\n                    temp_len = sent_len\n\
          \                else:\n                    temp_chunk.append(sent)\n  \
          \                  temp_len += sent_len\n\n            if temp_chunk:\n\
          \                chunks.append(\". \".join(temp_chunk) + \".\")\n\n    \
          \    # Normal paragraph fits or can be added\n        elif current_length\
          \ + para_len + 2 > effective_chunk_size:\n            # Current chunk is\
          \ full, start new one\n            if current_chunk:\n                chunks.append(\"\
          \\n\\n\".join(current_chunk))\n            current_chunk = [para]\n    \
          \        current_length = para_len\n        else:\n            # Add to\
          \ current chunk\n            current_chunk.append(para)\n            current_length\
          \ += para_len + 2  # +2 for \\n\\n\n\n    # Add final chunk\n    if current_chunk:\n\
          \        chunks.append(\"\\n\\n\".join(current_chunk))\n\n    # CRITICAL:\
          \ Final safety check - force-split any chunk that STILL exceeds limit\n\
          \    # This handles edge cases like very long sentences or code blocks\n\
          \    final_chunks = []\n    for chunk in chunks:\n        chunk_len = len(chunk)\n\
          \        if chunk_len > effective_chunk_size:\n            # Force-split\
          \ by characters as last resort\n            print(f\"SAFETY: Force-splitting\
          \ {chunk_len} char chunk into {effective_chunk_size} char pieces\")\n  \
          \          for i in range(0, chunk_len, effective_chunk_size):\n       \
          \         piece = chunk[i:i + effective_chunk_size]\n                if\
          \ len(piece) > 50:  # Filter very short pieces\n                    final_chunks.append(piece)\n\
          \        elif chunk_len > 50:  # Filter out very short chunks\n        \
          \    final_chunks.append(chunk)\n\n    chunks = final_chunks\n\n    # Verify\
          \ NO chunk exceeds limit\n    if chunks:\n        max_chunk_len = max(len(c)\
          \ for c in chunks)\n        print(f\"Created {len(chunks)} chunks (max length:\
          \ {max_chunk_len} chars, limit: {effective_chunk_size})\")\n        if max_chunk_len\
          \ > effective_chunk_size:\n            raise ValueError(f\"BUG: Chunk of\
          \ {max_chunk_len} chars STILL exceeds limit {effective_chunk_size}!\")\n\
          \    else:\n        print(\"No chunks created (document too short)\")\n\n\
          \    # Save chunks as simple JSON array of text strings\n    # LlamaStack\
          \ will compute embeddings server-side\n    chunk_data = [{\"chunk_id\":\
          \ i, \"text\": text} for i, text in enumerate(chunks)]\n\n    with open(output_chunks.path,\
          \ \"w\") as f:\n        json.dump(chunk_data, f)\n\n    print(f\"[OK] Created\
          \ {len(chunks)} chunks (embeddings will be computed by LlamaStack)\")\n\n"
        image: registry.access.redhat.com/ubi9/python-311:1-77
        resources:
          cpuLimit: 0.5
          cpuRequest: 0.25
          memoryLimit: 0.536870912
          memoryRequest: 0.268435456
          resourceCpuLimit: 500m
          resourceCpuRequest: 250m
          resourceMemoryLimit: 512Mi
          resourceMemoryRequest: 256Mi
    exec-download-from-s3:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - download_from_s3
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'boto3' 'requests'\
          \  &&  python3 -m pip install --quiet --no-warn-script-location 'kfp==2.14.6'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef download_from_s3(\n    input_uri: str,\n    s3_secret_mount_path:\
          \ str,\n    output_file: Output[Dataset],\n    minio_endpoint: str = \"\"\
          ,\n    minio_creds_b64: str = \"\"\n):\n    \"\"\"\n    Download document\
          \ from MinIO/S3.\n\n    Credentials are expected to be provided via a mounted\
          \ secret that matches the\n    canonical Data Processing layout (`S3_ENDPOINT_URL`,\
          \ `S3_ACCESS_KEY`,\n    `S3_SECRET_KEY`). The component reads credential\
          \ files directly, mirroring\n    the upstream Docling Kubeflow pipeline\
          \ pattern. For environments where\n    Kubernetes secret mounts are not\
          \ available (for example KFP v2 stripping\n    secret refs), provide `minio_endpoint`\
          \ and `minio_creds_b64` as a fallback.\n    \"\"\"\n    import os\n    from\
          \ pathlib import Path\n\n    import boto3\n    from botocore.client import\
          \ Config\n\n    print(f\"Downloading from: {input_uri}\")\n\n    endpoint_url\
          \ = \"\"\n    access_key = \"\"\n    secret_key = \"\"\n\n    def _read_secret(key:\
          \ str) -> str:\n        file_path = Path(s3_secret_mount_path) / key\n \
          \       if file_path.is_file():\n            return file_path.read_text().strip()\n\
          \        raise FileNotFoundError\n\n    try:\n        endpoint_url = _read_secret(\"\
          S3_ENDPOINT_URL\")\n        access_key = _read_secret(\"S3_ACCESS_KEY\"\
          )\n        secret_key = _read_secret(\"S3_SECRET_KEY\")\n        print(f\"\
          [OK] Loaded S3 credentials from secret at {s3_secret_mount_path}\")\n  \
          \  except FileNotFoundError:\n        if not minio_endpoint or not minio_creds_b64:\n\
          \            raise ValueError(\n                \"S3 secret files were not\
          \ found and fallback credentials were not provided. \"\n               \
          \ \"Provide `minio_endpoint` and `minio_creds_b64`, or mount the secret.\"\
          \n            )\n        import base64\n\n        creds_decoded = base64.b64decode(minio_creds_b64).decode(\"\
          utf-8\").strip()\n        access_key, secret_key = [c.strip() for c in creds_decoded.split(\"\
          :\", 1)]\n        endpoint_url = f\"http://{minio_endpoint}\" if not minio_endpoint.startswith(\"\
          http\") else minio_endpoint\n        print(\"[WARN] Falling back to inline\
          \ credentials (base64 parameter).\")\n\n    # Parse S3 URI\n    if input_uri.startswith(\"\
          s3://\"):\n        input_uri = input_uri[5:]\n\n    parts = input_uri.split(\"\
          /\", 1)\n    bucket = parts[0]\n    key = parts[1] if len(parts) > 1 else\
          \ \"\"\n\n    print(f\"Bucket: {bucket}, Key: {key}\")\n\n    # Configure\
          \ S3 client for MinIO/S3\n    s3_client = boto3.client(\n        \"s3\"\
          ,\n        endpoint_url=endpoint_url,\n        aws_access_key_id=access_key,\n\
          \        aws_secret_access_key=secret_key,\n        config=Config(signature_version=\"\
          s3v4\", s3={\"addressing_style\": \"path\"}),\n        region_name=\"us-east-1\"\
          ,\n    )\n\n    # Download file\n    output_path = output_file.path\n  \
          \  s3_client.download_file(bucket, key, output_path)\n\n    file_size =\
          \ os.path.getsize(output_path)\n    print(f\"[OK] Downloaded: {file_size}\
          \ bytes to {output_path}\")\n\n"
        image: registry.access.redhat.com/ubi9/python-311:1-77
        resources:
          cpuLimit: 1.0
          cpuRequest: 0.5
          memoryLimit: 1.073741824
          memoryRequest: 0.536870912
          resourceCpuLimit: '1'
          resourceCpuRequest: 500m
          resourceMemoryLimit: 1Gi
          resourceMemoryRequest: 512Mi
    exec-insert-via-llamastack:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - insert_via_llamastack
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'requests'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'kfp==2.14.6'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef insert_via_llamastack(\n    chunks_file: Input[Dataset],\n  \
          \  llamastack_url: str,\n    vector_db_id: str,\n    input_uri: str  # For\
          \ metadata\n) -> dict:\n    \"\"\"\n    Insert chunks via LlamaStack /v1/vector-io/insert\
          \ API\n\n    LlamaStack computes embeddings server-side - we only send content\
          \ + metadata.\n    This is faster and more efficient than pre-computing\
          \ embeddings.\n\n    Reference: https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/2.25/html/working_with_llama_stack/\n\
          \    \"\"\"\n    import requests\n    import json\n    import os\n\n   \
          \ print(f\"Inserting chunks via LlamaStack: {llamastack_url}\")\n    print(f\"\
          Target vector DB: {vector_db_id}\")\n\n    # Load chunks (just text, no\
          \ embeddings - LlamaStack computes them server-side)\n    with open(chunks_file.path,\
          \ \"r\") as f:\n        chunks_data = json.load(f)\n\n    print(f\"Loaded\
          \ {len(chunks_data)} chunks (embeddings computed server-side)\")\n\n   \
          \ # Extract source filename from input_uri for better document IDs\n   \
          \ source_name = os.path.basename(input_uri).replace(\".pdf\", \"\").replace(\"\
          s3://\", \"\").replace(\"/\", \"-\")\n\n    # Format chunks for LlamaStack\
          \ API\n    # Reference: https://llama-stack.readthedocs.io/en/v0.2.11/providers/vector_io/milvus.html\n\
          \    # Reference: https://milvus.io/docs/llama_stack_with_milvus.md\n  \
          \  #\n    # Milvus schema (v0.2.x): Int64 PK (auto_id=true), vector, chunk_content\
          \ (JSON)\n    # Provider auto-generates PK (chunk_id) and vector; we supply\
          \ content + metadata.\n    #\n    # Chunk structure (LlamaStack v0.2.x Chunk\
          \ model):\n    #   - content: string (chunk text) -> provider stores in\
          \ Milvus\n    #   - metadata: dict -> provider serializes to JSON for Milvus\n\
          \    #\n    # NOTE: v0.2.x provider manages chunk IDs internally. Do NOT\
          \ send stored_chunk_id.\n    llamastack_chunks = []\n    skipped_chunks\
          \ = 0\n    min_len = None\n    max_len = None\n    for i, item in enumerate(chunks_data):\n\
          \        content_text = item.get(\"text\") or item.get(\"content\") or \"\
          \"\n        if not isinstance(content_text, str):\n            content_text\
          \ = str(content_text)\n        stripped = content_text.strip()\n       \
          \ if not stripped:\n            skipped_chunks += 1\n            print(f\"\
          [SKIP] Chunk {i} empty after stripping; raw length={len(content_text)}\"\
          )\n            continue\n        content_text = stripped\n\n        # Calculate\
          \ token count (rough estimation: ~4 chars per token)\n        token_count\
          \ = len(content_text) // 4\n\n        metadata_dict = {\n            \"\
          document_id\": source_name,\n            \"chunk_index\": int(i),\n    \
          \        \"chunk_id\": int(item.get(\"chunk_id\", i)),\n            \"source_uri\"\
          : input_uri,\n            \"token_count\": int(token_count),\n         \
          \   \"character_count\": len(content_text),\n        }\n\n        extra_metadata\
          \ = item.get(\"metadata\")\n        if isinstance(extra_metadata, dict):\n\
          \            metadata_dict.update(extra_metadata)\n\n        text_len =\
          \ len(content_text)\n        min_len = text_len if min_len is None else\
          \ min(min_len, text_len)\n        max_len = text_len if max_len is None\
          \ else max(max_len, text_len)\n\n        # v0.2.x: Provider auto-generates\
          \ chunk IDs (no stored_chunk_id needed)\n        llamastack_chunks.append({\n\
          \            \"content\": content_text,\n            \"metadata\": metadata_dict\
          \  # Must be dict - LlamaStack API requires it\n        })\n\n    if skipped_chunks:\n\
          \        print(f\"Skipped {skipped_chunks} chunk(s) with empty content.\"\
          )\n    if llamastack_chunks:\n        print(f\"Prepared {len(llamastack_chunks)}\
          \ chunk(s); content length range {min_len}-{max_len}.\")\n\n    # Insert\
          \ via LlamaStack Vector IO API (with batching and retry)\n    print(f\"\
          Inserting {len(llamastack_chunks)} chunks via LlamaStack...\")\n\n    #\
          \ Batch insertion to avoid long single-call timeouts\n    BATCH_SIZE = 100\
          \  # Process 100 chunks at a time\n    total_inserted = 0\n    batches =\
          \ [llamastack_chunks[i:i + BATCH_SIZE] for i in range(0, len(llamastack_chunks),\
          \ BATCH_SIZE)]\n\n    print(f\"Split into {len(batches)} batch(es) of up\
          \ to {BATCH_SIZE} chunks\")\n\n    import time\n    for batch_idx, batch\
          \ in enumerate(batches):\n        batch_num = batch_idx + 1\n        print(f\"\
          Processing batch {batch_num}/{len(batches)} ({len(batch)} chunks)...\")\n\
          \n        # Validate batch content before calling LlamaStack\n        for\
          \ chunk_meta in batch:\n            content_val = chunk_meta.get(\"content\"\
          )\n            if not isinstance(content_val, str) or not content_val.strip():\n\
          \                raise ValueError(\n                    f\"Chunk missing\
          \ content prior to insert (batch {batch_num}): {chunk_meta.get('metadata')}\"\
          \n                )\n\n        # Retry logic with exponential backoff (per\
          \ Milvus guidance: up to 5 retries)\n        max_retries = 5\n        response\
          \ = None\n        for attempt in range(max_retries):\n            try:\n\
          \                # Timeout: ~3 sec/chunk + 120s overhead, max 600s\n   \
          \             timeout = min(600, len(batch) * 3 + 120)\n\n             \
          \   response = requests.post(\n                    f\"{llamastack_url}/v1/vector-io/insert\"\
          ,\n                    json={\n                        \"vector_db_id\"\
          : vector_db_id,\n                        \"chunks\": batch\n           \
          \         },\n                    headers={\"Content-Type\": \"application/json\"\
          },\n                    timeout=timeout\n                )\n\n         \
          \       if response.status_code != 200:\n                    print(f\" \
          \ ERROR: Batch {batch_num} returned {response.status_code}\")\n        \
          \            print(f\"  Response: {response.text}\")\n                 \
          \   response.raise_for_status()\n\n                # Parse response - handle\
          \ empty/null JSON\n                try:\n                    result = response.json()\n\
          \                except Exception as e:\n                    print(f\" \
          \ WARNING: Could not parse JSON response: {e}\")\n                    result\
          \ = None\n\n                batch_inserted = result.get(\"num_inserted\"\
          , len(batch)) if result else len(batch)\n                total_inserted\
          \ += batch_inserted\n                print(f\"  [OK] Batch {batch_num}:\
          \ {batch_inserted} chunks inserted\")\n                break  # Success\n\
          \n            except requests.exceptions.Timeout:\n                if attempt\
          \ < max_retries - 1:\n                    wait_time = min(30, 2 ** attempt)\
          \  # 1,2,4,8,16 (cap at 30s)\n                    print(f\"  Timeout on\
          \ batch {batch_num}, retry {attempt + 1}/{max_retries} after {wait_time}s...\"\
          )\n                    time.sleep(wait_time)\n                else:\n  \
          \                  print(f\"  FAILED: Batch {batch_num} timed out after\
          \ {max_retries} attempts\")\n                    raise\n            except\
          \ requests.exceptions.RequestException as e:\n                status_info\
          \ = \"\"\n                if response is not None:\n                   \
          \ status_info = f\" (status {response.status_code})\"\n                if\
          \ attempt < max_retries - 1:\n                    wait_time = min(30, 2\
          \ ** attempt)\n                    print(f\"  Request error on batch {batch_num}{status_info}:\
          \ {e}. Retry {attempt + 1}/{max_retries} after {wait_time}s...\")\n    \
          \                time.sleep(wait_time)\n                else:\n        \
          \            print(f\"  FAILED: Batch {batch_num} error after retries: {e}\"\
          )\n                    raise\n\n    print(f\"[OK] Successfully inserted\
          \ {total_inserted}/{len(llamastack_chunks)} chunks across {len(batches)}\
          \ batches\")\n    if llamastack_chunks:\n        print(f\"Sample document_id:\
          \ {llamastack_chunks[0]['metadata'].get('document_id')}\")\n\n    return\
          \ {\n        \"vector_db_id\": vector_db_id,\n        \"num_chunks\": total_inserted,\n\
          \        \"source\": input_uri,\n        \"status\": \"success\"\n    }\n\
          \n"
        image: registry.access.redhat.com/ubi9/python-311:1-77
        resources:
          cpuLimit: 0.5
          cpuRequest: 0.25
          memoryLimit: 0.536870912
          memoryRequest: 0.268435456
          resourceCpuLimit: 500m
          resourceCpuRequest: 250m
          resourceMemoryLimit: 512Mi
          resourceMemoryRequest: 256Mi
    exec-list-pdfs-in-s3:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - list_pdfs_in_s3
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'boto3'  && \
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.14.6'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef list_pdfs_in_s3(\n    s3_prefix: str,\n    s3_secret_mount_path:\
          \ str = \"/mnt/secrets\",\n    minio_endpoint: str = \"\",\n    minio_creds_b64:\
          \ str = \"\"\n) -> List[str]:\n    \"\"\"\n    Discover all PDF files in\
          \ an S3 prefix\n\n    Parameters:\n        s3_prefix: S3 path prefix (e.g.\
          \ \"s3://llama-files/scenario2-acme/\")\n        s3_secret_mount_path: Filesystem\
          \ path where S3 credentials are mounted\n        minio_endpoint: Optional\
          \ fallback endpoint (used if secret not mounted)\n        minio_creds_b64:\
          \ Optional fallback credentials in base64 (\"access:secret\")\n\n    Returns:\n\
          \        List of full S3 URIs for all PDFs found (e.g. [\"s3://bucket/file1.pdf\"\
          , ...])\n    \"\"\"\n    import os\n    from pathlib import Path\n\n   \
          \ import boto3\n    from botocore.client import Config\n\n    print(f\"\
          Discovering PDFs in: {s3_prefix}\")\n\n    endpoint_url = \"\"\n    access_key\
          \ = \"\"\n    secret_key = \"\"\n\n    def _read_secret(key: str) -> str:\n\
          \        file_path = Path(s3_secret_mount_path) / key\n        if file_path.is_file():\n\
          \            return file_path.read_text().strip()\n        raise FileNotFoundError\n\
          \n    try:\n        endpoint_url = _read_secret(\"S3_ENDPOINT_URL\")\n \
          \       access_key = _read_secret(\"S3_ACCESS_KEY\")\n        secret_key\
          \ = _read_secret(\"S3_SECRET_KEY\")\n        print(f\"[OK] Loaded S3 credentials\
          \ from secret at {s3_secret_mount_path}\")\n    except FileNotFoundError:\n\
          \        if not minio_endpoint or not minio_creds_b64:\n            raise\
          \ ValueError(\n                \"S3 secret files were not found and fallback\
          \ credentials were not provided. \"\n                \"Provide `minio_endpoint`\
          \ and `minio_creds_b64`, or mount the secret.\"\n            )\n       \
          \ import base64\n\n        creds_decoded = base64.b64decode(minio_creds_b64).decode(\"\
          utf-8\").strip()\n        access_key, secret_key = [c.strip() for c in creds_decoded.split(\"\
          :\", 1)]\n        endpoint_url = f\"http://{minio_endpoint}\" if not minio_endpoint.startswith(\"\
          http\") else minio_endpoint\n        print(\"[WARN] Falling back to inline\
          \ credentials (base64 parameter).\")\n\n    # Parse S3 prefix\n    if s3_prefix.startswith(\"\
          s3://\"):\n        s3_prefix = s3_prefix[5:]\n\n    # Remove trailing slash\n\
          \    s3_prefix = s3_prefix.rstrip('/')\n\n    parts = s3_prefix.split(\"\
          /\", 1)\n    bucket = parts[0]\n    prefix = parts[1] + \"/\" if len(parts)\
          \ > 1 else \"\"\n\n    print(f\"Bucket: {bucket}, Prefix: {prefix}\")\n\n\
          \    # Configure S3 client\n    s3_client = boto3.client(\n        \"s3\"\
          ,\n        endpoint_url=endpoint_url,\n        aws_access_key_id=access_key,\n\
          \        aws_secret_access_key=secret_key,\n        config=Config(signature_version=\"\
          s3v4\", s3={\"addressing_style\": \"path\"}),\n        region_name=\"us-east-1\"\
          ,\n    )\n\n    # List all objects with prefix\n    response = s3_client.list_objects_v2(Bucket=bucket,\
          \ Prefix=prefix)\n\n    if 'Contents' not in response:\n        print(f\"\
          No files found in {s3_prefix}\")\n        return []\n\n    # Filter for\
          \ PDFs only\n    pdf_keys = [\n        obj['Key'] for obj in response['Contents']\n\
          \        if obj['Key'].lower().endswith('.pdf')\n    ]\n\n    # Build full\
          \ S3 URIs\n    pdf_uris = [f\"s3://{bucket}/{key}\" for key in pdf_keys]\n\
          \n    print(f\"[OK] Found {len(pdf_uris)} PDF files:\")\n    for uri in\
          \ pdf_uris:\n        print(f\"  - {uri.split('/')[-1]}\")\n\n    return\
          \ pdf_uris\n\n"
        image: registry.access.redhat.com/ubi9/python-311:1-77
        resources:
          cpuLimit: 0.5
          cpuRequest: 0.25
          memoryLimit: 0.536870912
          memoryRequest: 0.268435456
          resourceCpuLimit: 500m
          resourceCpuRequest: 250m
          resourceMemoryLimit: 512Mi
          resourceMemoryRequest: 256Mi
    exec-process-with-docling:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - process_with_docling
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'requests'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'kfp==2.14.6'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef process_with_docling(\n    input_file: Input[Dataset],\n    docling_url:\
          \ str,\n    output_markdown: Output[Dataset]\n):\n    \"\"\"\n    Process\
          \ document with Docling to extract markdown (asynchronous API)\n\n    Uses\
          \ /v1/convert/file/async endpoint for robust long-running conversions.\n\
          \    This avoids server-side timeout issues (DOCLING_SERVE_MAX_SYNC_WAIT\
          \ default 120s).\n\n    Workflow:\n    1. Submit job to /v1/convert/file/async\n\
          \    2. Poll /v1/status/poll/{task_id} until completion\n    3. Fetch result\
          \ from /v1/result/{task_id}\n\n    Reference: https://github.com/docling-project/docling-serve/blob/main/docs/usage.md\n\
          \    Reference: https://github.com/docling-project/docling-serve/blob/main/docs/configuration.md\n\
          \    \"\"\"\n    import requests\n    import time\n    import os\n\n   \
          \ print(f\"Processing document with Docling (async): {docling_url}\")\n\n\
          \    # Read input file and get filename\n    filename = os.path.basename(input_file.path)\n\
          \    if not filename.endswith('.pdf'):\n        filename = 'document.pdf'\n\
          \n    file_size = os.path.getsize(input_file.path)\n    print(f\"Converting\
          \ document: {filename} ({file_size / 1024 / 1024:.2f} MB)\")\n\n    # Step\
          \ 1: Submit async job\n    print(f\"Submitting to /v1/convert/file/async...\"\
          )\n\n    with open(input_file.path, \"rb\") as f:\n        files = {\"files\"\
          : (filename, f, \"application/pdf\")}\n\n        response = requests.post(\n\
          \            f\"{docling_url}/v1/convert/file/async\",\n            files=files,\n\
          \            data={\"to_formats\": \"md\"},\n            timeout=30  # Short\
          \ timeout for submission only\n        )\n        response.raise_for_status()\n\
          \n    task = response.json()\n    task_id = task[\"task_id\"]\n    print(f\"\
          [OK] Task submitted: {task_id}\")\n    print(f\"    Initial status: {task.get('task_status',\
          \ 'unknown')}\")\n\n    # Step 2: Poll for completion\n    print(f\"Polling\
          \ for completion...\")\n    poll_count = 0\n    max_polls = 360  # 30 minutes\
          \ with 5s intervals\n\n    while task.get(\"task_status\") not in (\"success\"\
          , \"failure\"):\n        time.sleep(5)\n        poll_count += 1\n\n    \
          \    response = requests.get(\n            f\"{docling_url}/v1/status/poll/{task_id}\"\
          ,\n            timeout=10\n        )\n        response.raise_for_status()\n\
          \        task = response.json()\n\n        if poll_count % 12 == 0:  # Log\
          \ every minute\n            print(f\"  Check {poll_count}: {task.get('task_status')}\
          \ (position: {task.get('task_position', 'N/A')})\")\n\n        if poll_count\
          \ >= max_polls:\n            raise TimeoutError(f\"Task {task_id} did not\
          \ complete within 30 minutes\")\n\n    final_status = task.get(\"task_status\"\
          )\n    print(f\"[OK] Task completed with status: {final_status}\")\n\n \
          \   if final_status != \"success\":\n        raise RuntimeError(f\"Docling\
          \ task failed: {task}\")\n\n    # Step 3: Fetch result\n    print(f\"Fetching\
          \ result from /v1/result/{task_id}...\")\n    response = requests.get(\n\
          \        f\"{docling_url}/v1/result/{task_id}\",\n        timeout=30\n \
          \   )\n    response.raise_for_status()\n\n    print(f\"[OK] Result fetched\"\
          )\n\n    # Parse response\n    result = response.json()\n\n    # Log response\
          \ structure for debugging\n    print(f\"Response keys: {list(result.keys())}\"\
          )\n\n    # Extract markdown content from response\n    # Try different response\
          \ formats Docling might return\n    if \"markdown\" in result:\n       \
          \ # Format 1: Direct markdown field\n        markdown_content = result[\"\
          markdown\"]\n    elif \"documents\" in result and len(result[\"documents\"\
          ]) > 0:\n        # Format 2: Documents array with markdown\n        doc\
          \ = result[\"documents\"][0]\n        if isinstance(doc, dict) and \"markdown\"\
          \ in doc:\n            markdown_content = doc[\"markdown\"]\n        elif\
          \ isinstance(doc, dict) and \"md_content\" in doc:\n            markdown_content\
          \ = doc[\"md_content\"]\n        else:\n            markdown_content = str(doc)\n\
          \    elif \"document\" in result:\n        # Format 3: Single document object\
          \ with md_content\n        doc = result[\"document\"]\n        if isinstance(doc,\
          \ dict):\n            markdown_content = doc.get(\"md_content\", doc.get(\"\
          markdown\", str(doc)))\n        else:\n            markdown_content = str(doc)\n\
          \    elif \"content\" in result:\n        # Format 4: Direct content field\n\
          \        markdown_content = result[\"content\"]\n    else:\n        # Fallback:\
          \ stringify result and warn\n        markdown_content = str(result)\n  \
          \      print(f\"WARNING: Unexpected response format, stringifying result!\"\
          )\n        print(f\"Response keys: {list(result.keys())}\")\n        print(f\"\
          Sample: {str(result)[:500]}\")\n\n    # Write markdown output\n    with\
          \ open(output_markdown.path, \"w\") as f:\n        f.write(markdown_content)\n\
          \n    print(f\"[OK] Extracted {len(markdown_content)} characters of markdown\"\
          )\n    print(f\"Preview: {markdown_content[:200]}...\")\n\n"
        image: registry.access.redhat.com/ubi9/python-311:1-77
        resources:
          cpuLimit: 1.0
          cpuRequest: 0.5
          memoryLimit: 1.073741824
          memoryRequest: 0.536870912
          resourceCpuLimit: '1'
          resourceCpuRequest: 500m
          resourceMemoryLimit: 1Gi
          resourceMemoryRequest: 512Mi
    exec-split-pdf-list:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - split_pdf_list
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.14.6'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef split_pdf_list(pdf_uris: List[str], num_splits: int = 2) -> List[List[str]]:\n\
          \    \"\"\"\n    Split a list of PDF URIs into roughly even groups.\n\n\
          \    Args:\n        pdf_uris: List of full S3 URIs to process.\n       \
          \ num_splits: Desired number of splits (defaults to 2).\n\n    Returns:\n\
          \        A list of lists, each containing a subset of the original URIs.\n\
          \        Empty groups are filtered out.\n    \"\"\"\n    if num_splits <\
          \ 1:\n        raise ValueError(\"num_splits must be >= 1\")\n\n    # Ensure\
          \ deterministic ordering and remove duplicates while preserving order\n\
          \    seen = set()\n    ordered_uris = []\n    for uri in pdf_uris:\n   \
          \     if uri not in seen:\n            seen.add(uri)\n            ordered_uris.append(uri)\n\
          \n    if not ordered_uris:\n        return []\n\n    splits = [ordered_uris[i::num_splits]\
          \ for i in range(num_splits)]\n    return [group for group in splits if\
          \ group]\n\n"
        image: registry.access.redhat.com/ubi9/python-311:1-77
        resources:
          cpuLimit: 0.5
          cpuRequest: 0.25
          memoryLimit: 0.536870912
          memoryRequest: 0.268435456
          resourceCpuLimit: 500m
          resourceCpuRequest: 250m
          resourceMemoryLimit: 512Mi
          resourceMemoryRequest: 256Mi
pipelineInfo:
  description: RAG Ingestion Pipeline v1.0.2 - Refactored with modular components.
    Optimized server-side embeddings via LlamaStack Vector IO.
  name: data-processing-and-insertion
root:
  dag:
    tasks:
      for-loop-1:
        componentRef:
          name: comp-for-loop-1
        dependentTasks:
        - split-pdf-list
        inputs:
          parameters:
            pipelinechannel--chunk_size:
              componentInputParameter: chunk_size
            pipelinechannel--docling_url:
              componentInputParameter: docling_url
            pipelinechannel--llamastack_url:
              componentInputParameter: llamastack_url
            pipelinechannel--minio_creds_b64:
              componentInputParameter: minio_creds_b64
            pipelinechannel--minio_endpoint:
              componentInputParameter: minio_endpoint
            pipelinechannel--s3_secret_mount_path:
              componentInputParameter: s3_secret_mount_path
            pipelinechannel--split-pdf-list-Output:
              taskOutputParameter:
                outputParameterKey: Output
                producerTask: split-pdf-list
            pipelinechannel--vector_db_id:
              componentInputParameter: vector_db_id
        parameterIterator:
          itemInput: pipelinechannel--split-pdf-list-Output-loop-item
          items:
            inputParameter: pipelinechannel--split-pdf-list-Output
        taskInfo:
          name: process-pdf-group
      list-pdfs-in-s3:
        cachingOptions: {}
        componentRef:
          name: comp-list-pdfs-in-s3
        inputs:
          parameters:
            minio_creds_b64:
              componentInputParameter: minio_creds_b64
            minio_endpoint:
              componentInputParameter: minio_endpoint
            s3_prefix:
              componentInputParameter: s3_prefix
            s3_secret_mount_path:
              componentInputParameter: s3_secret_mount_path
        taskInfo:
          name: list-pdfs-in-s3
      split-pdf-list:
        cachingOptions: {}
        componentRef:
          name: comp-split-pdf-list
        dependentTasks:
        - list-pdfs-in-s3
        inputs:
          parameters:
            num_splits:
              componentInputParameter: num_splits
            pdf_uris:
              taskOutputParameter:
                outputParameterKey: Output
                producerTask: list-pdfs-in-s3
        taskInfo:
          name: split-pdf-list
  inputDefinitions:
    parameters:
      cache_buster:
        defaultValue: ''
        isOptional: true
        parameterType: STRING
      chunk_size:
        defaultValue: 512.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      docling_url:
        defaultValue: http://docling-service.private-ai-demo.svc:5001
        isOptional: true
        parameterType: STRING
      llamastack_url:
        defaultValue: http://llama-stack-service.private-ai-demo.svc:8321
        isOptional: true
        parameterType: STRING
      minio_creds_b64:
        defaultValue: ''
        isOptional: true
        parameterType: STRING
      minio_endpoint:
        defaultValue: minio.model-storage.svc:9000
        isOptional: true
        parameterType: STRING
      num_splits:
        defaultValue: 2.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      s3_prefix:
        defaultValue: s3://llama-files/sample/
        description: S3 folder path containing PDFs (e.g. "s3://llama-files/scenario2-acme/")
        isOptional: true
        parameterType: STRING
      s3_secret_mount_path:
        defaultValue: /mnt/secrets
        isOptional: true
        parameterType: STRING
      vector_db_id:
        defaultValue: acme_corporate
        description: Target collection name (all docs go here)
        isOptional: true
        parameterType: STRING
schemaVersion: 2.1.0
sdkVersion: kfp-2.14.6
