# Stage 2: Model Alignment - RAG Implementation

This directory contains the implementation of Retrieval-Augmented Generation (RAG) for the Private AI Demo, using Docling for document processing, LlamaStack for orchestration, and Milvus for vector storage.

## ğŸ“ Directory Structure

```
stage2-model-alignment/
â”œâ”€â”€ deploy.sh                      # Main deployment script (deploys + triggers ingestion)
â”œâ”€â”€ run-batch-ingestion.sh         # Manual ingestion script for specific scenarios
â”œâ”€â”€ upload-to-minio.sh             # Upload documents to MinIO utility
â”œâ”€â”€ scenario-docs/                 # Source documents for ingestion
â”‚   â”œâ”€â”€ scenario1-red-hat/         # Red Hat RHOAI RAG guide (1 PDF)
â”‚   â”œâ”€â”€ scenario2-acme/            # ACME corporate docs (6 PDFs)
â”‚   â””â”€â”€ scenario3-eu-ai-act/       # EU AI Act documents (3 PDFs)
â”œâ”€â”€ kfp/                           # Kubeflow Pipelines definitions
â”‚   â”œâ”€â”€ pipeline.py                # Main pipeline definitions
â”‚   â”œâ”€â”€ components/                # Modular KFP components
â”‚   â”‚   â”œâ”€â”€ chunk_markdown.py      # Chunking component
â”‚   â”‚   â”œâ”€â”€ download_from_s3.py    # S3 download component
â”‚   â”‚   â”œâ”€â”€ insert_via_llamastack.py # Milvus insertion via LlamaStack
â”‚   â”‚   â”œâ”€â”€ list_pdfs_in_s3.py     # S3 listing component
â”‚   â”‚   â”œâ”€â”€ process_with_docling.py # Docling processing component
â”‚   â”‚   â”œâ”€â”€ split_pdf_list.py      # PDF list splitting for parallel processing
â”‚   â”‚   â””â”€â”€ verify_ingestion.py    # Ingestion verification component
â”‚   â””â”€â”€ utils/                     # KFP helper utilities
â”‚       â”œâ”€â”€ kfp-api-helpers.sh     # KFP API interaction helpers
â”‚       â””â”€â”€ programmatic-access.sh # OAuth authentication example
â””â”€â”€ README.md                      # This file
```

## ğŸš€ Quick Start

### 1. Deploy Stage 2 Infrastructure

```bash
./deploy.sh
```

This script provides **one-click deployment**:

1. **Deploys all infrastructure:**
   - Docling service (PDF processing)
   - LlamaStack (RAG orchestration)
   - Guardrails Orchestrator (safety shields + policy enforcement)
   - LlamaStack Playground UI
   - Milvus vector database
   - KFP Data Science Pipelines

2. **Automatically uploads documents to MinIO:**
   - Scans `scenario-docs/` for PDF files
   - Uploads all documents to corresponding S3 paths
   - Skips upload if MinIO already has content

3. **Automatically triggers ingestion:**
   - Launches batch ingestion for all 3 scenarios
   - Creates pipeline runs in KFP
   - Populates Milvus collections with embeddings

**Result:** Run `./deploy.sh` once and get a fully operational RAG system with data!

### 2. Re-upload Documents (Optional)

The `deploy.sh` script automatically uploads documents from `scenario-docs/` to MinIO. However, if you need to upload additional documents or replace existing ones:

```bash
# Upload a single document
./upload-to-minio.sh /path/to/document.pdf s3://llama-files/scenario2-acme/document.pdf

# Upload entire scenario
for pdf in scenario-docs/scenario2-acme/*.pdf; do
  filename=$(basename "$pdf")
  ./upload-to-minio.sh "$pdf" "s3://llama-files/scenario2-acme/$filename"
done
```

### 3. Manual Ingestion (Optional)

The `deploy.sh` script automatically uploads documents and triggers ingestion. However, if you need to manually re-run ingestion for a specific scenario:

```bash
./run-batch-ingestion.sh <scenario>
```

Available scenarios:
- `acme` - ACME Corporate lithography documentation (6 PDFs â†’ ~32 chunks)
- `redhat` - Red Hat OpenShift AI RAG guide (1 PDF â†’ ~135 chunks)
- `eu-ai-act` - EU AI Act official documents (3 PDFs â†’ ~953 chunks)

### 4. Guardrails Configuration

The Guardrails Orchestrator is fully declarative via GitOps. Before deploying you must provide secrets in the project `.env` (see `docs/SETUP.md`):

```bash
export GUARDRAILS_OPENAI_API_KEY=...
./deploy.sh  # Creates secret + syncs GitOps manifests
```

Configuration files live in `gitops/stage02-model-alignment/guardrails/`:

- `guardrails-configmap.yaml` â€“ detector presets (PII + prompt-injection)
- `guardrails-orchestrator.yaml` â€“ runtime definition + OTEL telemetry
- `guardrails-route.yaml` â€“ external access for policy testing

The LlamaStack Playground reads the Guardrails route to enforce policies in the RAG UI.

**Examples:**
```bash
# Re-run ingestion for ACME scenario
./run-batch-ingestion.sh acme

# Re-run ingestion for all scenarios
for scenario in redhat acme eu-ai-act; do
  ./run-batch-ingestion.sh $scenario
done
```

## ğŸ“Š Pipeline Architecture

The batch ingestion pipeline follows this flow:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  List PDFs      â”‚  List all PDFs from S3 prefix
â”‚  from S3        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Split into     â”‚  Divide PDFs into groups for parallel processing
â”‚  Groups         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ParallelFor    â”‚  Process each group in parallel
â”‚  (Groups)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ParallelFor    â”‚  Process each PDF in parallel
â”‚  (PDFs)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Download       â”‚                     â”‚  Process with   â”‚
â”‚  from S3        â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Docling        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                                                  â–¼
                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                         â”‚  Chunk          â”‚
                                         â”‚  Markdown       â”‚
                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                                                  â–¼
                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                         â”‚  Insert via     â”‚
                                         â”‚  LlamaStack     â”‚
                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Features:
- **Parallel Processing**: PDFs are split into groups and processed in parallel for optimal throughput
- **Server-Side Embeddings**: LlamaStack handles embeddings using Granite model
- **Automatic Metadata**: Document ID, source URI, chunk index, and token count automatically added
- **Caching Disabled**: Each run is fresh (no cached results)
- **HNSW Indexing**: Milvus uses HNSW index for fast similarity search

## ğŸ”§ Upload Documents to MinIO

```bash
# Upload a single document
./upload-to-minio.sh /path/to/document.pdf s3://llama-files/scenario2-acme/document.pdf

# Upload all PDFs from a directory
for pdf in scenario-docs/scenario2-acme/*.pdf; do
  filename=$(basename "$pdf")
  ./upload-to-minio.sh "$pdf" "s3://llama-files/scenario2-acme/$filename"
done
```

This utility handles document uploads to MinIO. All other operations (schema management, testing, ingestion) are handled by the main scripts or through the UI.

## ğŸ“š Documentation

For detailed documentation, see:
- `docs/03-STAGE2-RAG/STAGE2-README.md` - Comprehensive Stage 2 overview
- `docs/03-STAGE2-RAG/PIPELINE-NAMING-VERSIONING.md` - Pipeline naming & versioning conventions
- `docs/03-STAGE2-RAG/PER-DOCUMENT-INGESTION.md` - Per-document ingestion guide
- `docs/03-STAGE2-RAG/KFP-BEST-PRACTICES-IMPLEMENTATION.md` - KFP implementation patterns
- `docs/03-STAGE2-RAG/FINAL-STATUS-2025-11-07.md` - Final implementation status

## ğŸ¯ Current Status

**Production Ready** âœ…

- âœ… Infrastructure deployed via GitOps
- âœ… Automated ingestion on first deploy
- âœ… 10 PDFs â†’ 1,120 chunks in Milvus
- âœ… RAG retrieval working
- âœ… LlamaStack Playground UI operational
- âœ… All three scenarios validated

### Milvus Collections

| Collection | Documents | Chunks | Status |
|------------|-----------|--------|--------|
| `red_hat_docs` | 1 PDF | 135 | âœ… Ready |
| `acme_corporate` | 6 PDFs | 32 | âœ… Ready |
| `eu_ai_act` | 3 PDFs | 953 | âœ… Ready |

### Access Points

- **LlamaStack Playground**: https://llamastack-private-ai-demo.apps.cluster-gmgrr.gmgrr.sandbox5294.opentlc.com
- **KFP UI**: https://ds-pipeline-dspa-private-ai-demo.apps.cluster-gmgrr.gmgrr.sandbox5294.opentlc.com
- **LlamaStack API**: http://llama-stack-service.private-ai-demo.svc:8321

## ğŸ” Troubleshooting

### Pipeline Not Running?

Check caching is disabled:
```bash
# Verify cache_buster parameter is changing
grep "cache_buster" run-batch-ingestion.sh
```

### No Data in Milvus?

1. Check LlamaStack logs:
   ```bash
   oc logs -n private-ai-demo deployment/llama-stack -f
   ```

2. Verify data in Milvus:
   ```bash
   oc exec -n private-ai-demo deployment/milvus-standalone -- \
     python3 -c "from pymilvus import connections, Collection; connections.connect(host='localhost', port='19530'); print(Collection('acme_corporate').num_entities)"
   ```

### MinIO Upload Failing?

Check credentials and use the upload utility:
```bash
# Verify MinIO credentials
oc get secret minio-credentials -n model-storage -o jsonpath='{.data.MINIO_ROOT_USER}' | base64 -d

# Upload using the utility script
./upload-to-minio.sh /path/to/document.pdf s3://llama-files/scenario2-acme/document.pdf
```

### Need to Reset Milvus Collections?

Drop and recreate collections using kubectl:
```bash
# Delete a collection
oc exec -n private-ai-demo deployment/milvus-standalone -- \
  python3 -c "from pymilvus import connections, utility; connections.connect(host='localhost', port='19530'); utility.drop_collection('acme_corporate')"

# Collection will be auto-recreated by LlamaStack provider on next insert
```

## ğŸ“ Support

For issues or questions, refer to the comprehensive documentation in `docs/03-STAGE2-RAG/`.

