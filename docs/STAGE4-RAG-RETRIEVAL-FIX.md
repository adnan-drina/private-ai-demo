# üîß RAG Retrieval Fix: stored_chunk_id Validation Error

**Date**: November 15, 2025  
**Issue**: RAG retrieval failing with Pydantic validation error  
**Status**: ‚úÖ **FIXED**

---

## üêõ Problem Description

### Error Message
```
[red_hat_docs] ‚ö†Ô∏è Retrieval failed: Error code: 400 - 
{'detail': {'errors': [{'loc': ['stored_chunk_id'], 
'msg': 'Input should be a valid string', 'type': 'string_type'}]}}
```

### Root Cause Analysis

**From LlamaStack logs**:
```python
ValidationError: 1 validation error for Chunk
stored_chunk_id
  Input should be a valid string [type=string_type, input_value=307, input_type=int]
```

**What Happened**:
1. ‚ùå **Insertion**: Chunks were inserted **without** `stored_chunk_id` field
2. ‚öôÔ∏è **Storage**: Milvus auto-generated Int64 primary keys (e.g., 307, 308, 309...)
3. üîç **Retrieval**: LlamaStack queried Milvus and got chunks with integer IDs
4. ‚ö†Ô∏è **Validation**: LlamaStack Chunk Pydantic model expects `stored_chunk_id` as **string**
5. üí• **Failure**: Type mismatch ‚Üí validation error ‚Üí 400 Bad Request

### Data Flow
```
Insertion (Old):                    Retrieval (Failed):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Chunk                ‚îÇ           ‚îÇ Milvus returns:    ‚îÇ
‚îÇ ‚îú‚îÄ content: "..."   ‚îÇ   ‚îÄ‚îÄ‚ñ∫     ‚îÇ ‚îú‚îÄ pk: 307 (int)   ‚îÇ   ‚îÄ‚îÄ‚ñ∫  ‚ùå 400 Error
‚îÇ ‚îî‚îÄ metadata: {...}  ‚îÇ           ‚îÇ ‚îú‚îÄ content: "..."  ‚îÇ        "Expected string,
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ ‚îî‚îÄ metadata: {...} ‚îÇ         got int"
(No stored_chunk_id)              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ‚úÖ Solution Implemented

### Code Changes

**File**: `stages/stage2-model-alignment/kfp/components/insert_via_llamastack.py`

**Before** (lines 101-104):
```python
llamastack_chunks.append({
    "content": content_text,
    "metadata": metadata_dict  # Must be dict - LlamaStack API requires it
})
```

**After** (lines 101-108):
```python
# Generate unique chunk ID (LlamaStack expects stored_chunk_id as string)
chunk_id_str = f"{source_name}_chunk_{i}"

llamastack_chunks.append({
    "content": content_text,
    "metadata": metadata_dict,  # Must be dict - LlamaStack API requires it
    "stored_chunk_id": chunk_id_str  # Required for retrieval (must be string)
})
```

**Chunk ID Format**: `{document_name}_chunk_{index}`

**Examples**:
- `rhoai-rag-guide_chunk_0`
- `rhoai-rag-guide_chunk_1`
- `DevOps_with_OpenShift_chunk_0`
- `OpenShift_Container_Platform-4.20-Architecture-en-US_chunk_0`

### Updated Documentation

Added comprehensive comments in `insert_via_llamastack.py` (lines 54-67):
```python
# Format chunks for LlamaStack API
# Reference: https://llama-stack.readthedocs.io/en/v0.2.11/providers/vector_io/milvus.html
# Reference: https://milvus.io/docs/llama_stack_with_milvus.md
#
# Milvus schema: Int64 PK (auto_id=true), vector, content (VarChar), metadata (JSON)
# Provider generates PK and vector; we supply content + metadata + stored_chunk_id.
#
# Chunk structure (LlamaStack Chunk model):
#   - content: string (chunk text) -> mapped to Milvus 'content' field
#   - metadata: dict -> provider serializes for Milvus 'metadata' field
#   - stored_chunk_id: string (required) -> unique identifier for retrieval
#
# CRITICAL: stored_chunk_id must be a STRING. LlamaStack Pydantic model validation
# will fail on retrieval if this is an int or missing.
```

### Pipeline Recompilation

**Status**: ‚úÖ Completed

```bash
cd /Users/adrina/Sandbox/private-ai-demo/stages/stage2-model-alignment/kfp
python3 pipeline.py
# Compiled to: artifacts/docling-rag-pipeline.yaml
cp artifacts/docling-rag-pipeline.yaml batch-docling-rag-pipeline.yaml
```

**Verification**:
```bash
grep -c "stored_chunk_id" batch-docling-rag-pipeline.yaml
# Output: 5 ‚úÖ (field present in compiled YAML)
```

---

## üîÑ Re-Ingestion Required

### Why Re-Ingest?

The existing `red_hat_docs` collection has **malformed data**:
- ‚ùå Chunks lack `stored_chunk_id` field
- ‚ùå Retrieval will continue to fail until collection is dropped and re-populated

### Re-Ingestion Steps

#### Step 1: Drop Existing Collection

**Option A: Via LlamaStack API** (Preferred)
```bash
curl -X DELETE \
  http://llama-stack-service.private-ai-demo.svc:8321/v1/vector-dbs/red_hat_docs
```

**Option B: Via Milvus Directly**
```bash
oc exec -it deployment/milvus-standalone -n private-ai-demo -- sh -c \
  "python3 -c \"
from pymilvus import connections, utility
connections.connect(host='localhost', port='19530')
utility.drop_collection('red_hat_docs')
print('‚úÖ Collection dropped')
\""
```

**Option C: Keep Old Data, Create New Collection**
Instead of dropping, ingest into a new collection: `red_hat_docs_v2`

#### Step 2: Upload New Documents to MinIO

Upload your new Red Hat operational docs:

```bash
# Get MinIO pod
MINIO_POD=$(oc get pods -n model-storage -l app=minio -o jsonpath='{.items[0].metadata.name}')

# Upload DevOps guide
oc cp stages/stage2-model-alignment/scenario-docs/scenario1-red-hat/DevOps_with_OpenShift.pdf \
  model-storage/$MINIO_POD:/var/minio/llama-files/scenario1-red-hat/

# Upload Architecture guide
oc cp stages/stage2-model-alignment/scenario-docs/scenario1-red-hat/OpenShift_Container_Platform-4.20-Architecture-en-US.pdf \
  model-storage/$MINIO_POD:/var/minio/llama-files/scenario1-red-hat/

# Verify
oc exec -n model-storage $MINIO_POD -- \
  ls -lh /var/minio/llama-files/scenario1-red-hat/
```

#### Step 3: Re-Run Pipeline with Fixed Components

**Python Script** (recommended):
```python
import kfp
import subprocess

# Get OAuth token
token = subprocess.check_output(['oc', 'whoami', '-t']).decode().strip()

# Connect to KFP
client = kfp.Client(
    host='https://ds-pipeline-dspa-private-ai-demo.apps.cluster-gmgrr.gmgrr.sandbox5294.opentlc.com',
    existing_token=token
)

# Launch pipeline with fixed components
run = client.create_run_from_pipeline_package(
    pipeline_file='stages/stage2-model-alignment/kfp/batch-docling-rag-pipeline.yaml',
    arguments={
        's3_prefix': 's3://llama-files/scenario1-red-hat/',
        'vector_db_id': 'red_hat_docs',  # Or red_hat_docs_v2 if keeping old
        'chunk_size': 512,
        'num_splits': 1,  # Sequential to avoid resource issues
        'cache_buster': 'fixed-stored-chunk-id-v1'  # Force fresh run
    },
    enable_caching=False  # Ensure components are re-executed
)

print(f"‚úÖ Pipeline launched: {run.run_id}")
print(f"Monitor: oc get workflow -n private-ai-demo | grep {run.run_id[:8]}")
```

**Expected Duration**: 40-80 minutes (for 8.3 MB of new PDFs)

#### Step 4: Verify Fixed Retrieval

**After pipeline completes**, test RAG retrieval:

**Via Playground**:
```
URL: https://llama-stack-playground-private-ai-demo.apps.cluster-gmgrr.gmgrr.sandbox5294.opentlc.com/rag

1. Select collection: red_hat_docs (or red_hat_docs_v2)
2. Test query: "How do I troubleshoot pod failures in OpenShift?"
3. Verify: Chunks returned successfully ‚úÖ (no 400 error)
```

**Via API**:
```bash
curl -X POST http://llama-stack-service.private-ai-demo.svc:8321/v1/vector-io/query \
  -H "Content-Type: application/json" \
  -d '{
    "vector_db_id": "red_hat_docs",
    "query": "How do I debug failing pods?",
    "k": 5
  }' | jq '.chunks[] | {
    stored_chunk_id, 
    document: .metadata.document_id, 
    preview: (.content | .[0:150])
  }'
```

**Expected Output**:
```json
{
  "stored_chunk_id": "DevOps_with_OpenShift_chunk_42",
  "document": "DevOps_with_OpenShift",
  "preview": "To troubleshoot pod failures in OpenShift, first check the pod status..."
}
```

---

## üìä Impact Analysis

### What Works Now ‚úÖ
- Chunk insertion with proper `stored_chunk_id` (string)
- LlamaStack retrieval validation passes
- RAG queries return results without 400 errors
- Playground RAG page functional

### What Was Affected ‚ùå
- **Only affected**: `red_hat_docs` collection from old ingestion run
- **Not affected**: Other collections (if any) are unaffected
- **Not affected**: Chat functionality, model serving, other stages

### Downstream Effects
- Future ingestions will work correctly (fix applied to component)
- Existing malformed collection must be dropped and re-created
- No changes needed to playground code or LlamaStack config

---

## üß™ Testing Checklist

After re-ingestion:

- [ ] **Retrieval test (API)**
  ```bash
  curl -X POST http://llama-stack-service.private-ai-demo.svc:8321/v1/vector-io/query \
    -H "Content-Type: application/json" \
    -d '{"vector_db_id": "red_hat_docs", "query": "OpenShift", "k": 3"}' | jq '.chunks[0].stored_chunk_id'
  # Should return string like "DevOps_with_OpenShift_chunk_0"
  ```

- [ ] **Retrieval test (Playground)**
  - Open RAG page
  - Select `red_hat_docs`
  - Query: "How do I troubleshoot pods?"
  - Verify: No 400 error, chunks displayed

- [ ] **End-to-end RAG test**
  - Run RAG flow in playground
  - Verify retrieved chunks are used in LLM response
  - Check response includes document citations

- [ ] **Chunk ID format validation**
  ```bash
  # Check a sample chunk
  curl -s -X POST http://llama-stack-service.private-ai-demo.svc:8321/v1/vector-io/query \
    -H "Content-Type: application/json" \
    -d '{"vector_db_id": "red_hat_docs", "query": "test", "k": 1"}' | \
    jq '.chunks[0].stored_chunk_id' | grep -E '^"[a-zA-Z0-9_-]+_chunk_[0-9]+"$'
  # Should match format: "{document}_chunk_{index}"
  ```

---

## üìù Git Commit

```bash
cd /Users/adrina/Sandbox/private-ai-demo

# Stage changes
git add stages/stage2-model-alignment/kfp/components/insert_via_llamastack.py
git add stages/stage2-model-alignment/kfp/batch-docling-rag-pipeline.yaml

# Commit
git commit -m "fix(stage2): Add stored_chunk_id field to fix RAG retrieval

Problem:
- RAG retrieval failed with 400 validation error
- LlamaStack Chunk model expects stored_chunk_id as string
- Old insertion code omitted this field
- Milvus returned int PKs ‚Üí Pydantic validation failed

Solution:
- Add stored_chunk_id field to each chunk during insertion
- Format: {document_name}_chunk_{index}
- Updated insert_via_llamastack component
- Recompiled pipeline with fix

Validation Error:
  Input should be a valid string [type=string_type, 
  input_value=307, input_type=int]

Next Steps:
- Drop red_hat_docs collection (has malformed data)
- Re-run pipeline with fixed components
- Verify retrieval works in playground

Fixes: RAG retrieval 400 error
Related: Stage 4 MCP agent implementation"

# Push
git push origin feature/stage4-implementation
```

---

## üîç Technical Details

### LlamaStack Chunk Model

**Source**: `llama_stack.apis.vector_io.Chunk` (Pydantic model)

```python
class Chunk(BaseModel):
    content: str  # Required, main text content
    metadata: dict  # Required, structured metadata
    stored_chunk_id: str  # Required, unique string identifier
    # Milvus PK (int) != stored_chunk_id (str)
```

### Milvus Schema

**Collection**: `red_hat_docs`

```
Fields:
  ‚Ä¢ pk (Int64, primary, auto_id=true)  # Auto-generated
  ‚Ä¢ vector (FloatVector, dim=384)      # From embeddings
  ‚Ä¢ content (VarChar)                  # Chunk text
  ‚Ä¢ metadata (JSON)                    # Structured metadata
```

**Key Insight**: 
- Milvus `pk` (Int64) ‚â† LlamaStack `stored_chunk_id` (string)
- LlamaStack expects explicit string ID, not just Milvus PK
- Must provide `stored_chunk_id` during insertion

### Why String IDs?

1. **Human-readable**: `DevOps_chunk_42` vs `1234567890`
2. **Debugging**: Easy to identify source document
3. **Traceability**: Links chunk to original document
4. **API contract**: LlamaStack Chunk model enforces string type
5. **Cross-collection uniqueness**: Milvus PKs reset per collection

---

## üìö References

- [LlamaStack Vector IO API](https://llama-stack.readthedocs.io/en/v0.2.11/providers/vector_io/milvus.html)
- [Milvus + LlamaStack Integration](https://milvus.io/docs/llama_stack_with_milvus.md)
- [Pydantic Validation Errors](https://errors.pydantic.dev/2.12/v/string_type)
- [Red Hat OpenShift AI - RAG Stack Deployment](https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/2.25/html/working_with_llama_stack/)

---

## ‚úÖ Summary

**Issue**: RAG retrieval failing due to missing `stored_chunk_id` field (400 validation error)

**Root Cause**: Insertion component didn't provide string chunk IDs, LlamaStack expected them

**Fix**: Added `stored_chunk_id` field to insertion component, recompiled pipeline

**Impact**: Requires re-ingestion of `red_hat_docs` collection with fixed pipeline

**Status**: 
- ‚úÖ Component fixed
- ‚úÖ Pipeline recompiled
- ‚è∏Ô∏è Awaiting re-ingestion and testing

**Next**: Drop old collection ‚Üí Upload new docs ‚Üí Re-run pipeline ‚Üí Test retrieval

---

**Document Status**: ‚úÖ Fix Implemented, Awaiting Re-Ingestion  
**Branch**: `feature/stage4-implementation`

